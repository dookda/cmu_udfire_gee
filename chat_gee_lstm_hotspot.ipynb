{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6185e21",
   "metadata": {},
   "source": [
    "\n",
    "# Hotspot Prediction with GEE + LSTM (Weekly)\n",
    "\n",
    "This notebook shows how to:\n",
    "1. Initialize Google Earth Engine (GEE) in Python.\n",
    "2. Build **weekly features** over an AOI (default: Nan Province, Thailand).\n",
    "3. Train an **LSTM** to predict weekly hotspot counts (from VIIRS FIRMS).\n",
    "4. Evaluate and forecast **2025** hotspots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d0ec0",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85daa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If running in Colab, uncomment:\n",
    "# !pip install -q earthengine-api geemap pandas numpy scikit-learn tensorflow==2.16.1 matplotlib\n",
    "\n",
    "import math, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ee, geemap\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ecb1c",
   "metadata": {},
   "source": [
    "## 2) Authenticate & Initialize GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a75f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "print(\"GEE initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f44eaf",
   "metadata": {},
   "source": [
    "## 3) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COUNTRY = 'Thailand'\n",
    "PROVINCE = 'Nan'\n",
    "START_TRAIN = '2020-01-01'\n",
    "END_TRAIN   = '2024-12-31'\n",
    "PRED_YEAR   = 2025\n",
    "SEQ_LEN = 8\n",
    "TARGET_MODE = 'count'  # or 'binary'\n",
    "USE_VIIRS = True       # True: VIIRS (NASA/LANCE/SNPP_VIIRS/C2), False: MODIS FIRMS (FIRMS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48014bcf",
   "metadata": {},
   "source": [
    "### 3.1 AOI from GAUL (with fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf25597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_aoi_from_gaul(country, province):\n",
    "    try:\n",
    "        admin1 = ee.FeatureCollection('FAO/GAUL_SIMPLIFIED_500m/2015/level1')\n",
    "        aoi = (admin1\n",
    "               .filter(ee.Filter.eq('ADM0_NAME', country))\n",
    "               .filter(ee.Filter.eq('ADM1_NAME', province))\n",
    "               .geometry())\n",
    "        _ = aoi.area(1).getInfo()  # trigger error if not found\n",
    "        return aoi\n",
    "    except Exception as e:\n",
    "        print('GAUL lookup failed, using fallback bbox. Error:', e)\n",
    "        return ee.Geometry.Rectangle([100.2, 18.0, 101.5, 19.5])\n",
    "\n",
    "AOI = get_aoi_from_gaul(COUNTRY, PROVINCE)\n",
    "m = geemap.Map(center=[18.8, 100.8], zoom=7)\n",
    "m.addLayer(AOI, {'color':'red'}, 'AOI')\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85930e67",
   "metadata": {},
   "source": [
    "## 4) Collections & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viirs = ee.ImageCollection('NASA/LANCE/SNPP_VIIRS/C2')\n",
    "firms_modis = ee.ImageCollection('FIRMS')\n",
    "chirps = ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')\n",
    "mod13q1 = ee.ImageCollection('MODIS/061/MOD13Q1')\n",
    "mod11a2 = ee.ImageCollection('MODIS/061/MOD11A2')\n",
    "srtm = ee.Image('USGS/SRTMGL1_003')\n",
    "slope = ee.Terrain.slope(srtm).rename('slope')\n",
    "\n",
    "def week_edges(start_date, end_date):\n",
    "    start = ee.Date(start_date)\n",
    "    end = ee.Date(end_date)\n",
    "    dates = []\n",
    "    d = start\n",
    "    while d.millis().getInfo() < end.millis().getInfo():\n",
    "        dates.append(d.format('YYYY-MM-dd').getInfo())\n",
    "        d = d.advance(1, 'week')\n",
    "    return dates\n",
    "\n",
    "def viirs_week_image(start, end):\n",
    "    ic = viirs.filterDate(start, end)\n",
    "    fire = ic.map(lambda img: img.select('confidence').gte(1).rename('fire'))\n",
    "    return fire.sum().rename('fire')\n",
    "\n",
    "def firms_modis_week_image(start, end):\n",
    "    ic = firms_modis.filterDate(start, end)\n",
    "    fire = ic.map(lambda img: img.select('confidence').gte(30).rename('fire'))\n",
    "    return fire.sum().rename('fire')\n",
    "\n",
    "def chirps_week_sum(start, end):\n",
    "    return chirps.filterDate(start, end).select('precipitation').sum().rename('precip')\n",
    "\n",
    "def ndvi_week_mean(start, end):\n",
    "    # NDVI scaled by 0.0001\n",
    "    return mod13q1.filterDate(start, end).select('NDVI').mean().multiply(0.0001).rename('ndvi')\n",
    "\n",
    "def lst_week_mean_c(start, end):\n",
    "    lstK = mod11a2.filterDate(start, end).select('LST_Day_1km').mean().multiply(0.02)\n",
    "    return lstK.subtract(273.15).rename('lst_c')\n",
    "\n",
    "def region_mean(img, region, scale):\n",
    "    return img.reduceRegion(ee.Reducer.mean(), region, scale, maxPixels=1e13)\n",
    "\n",
    "def region_sum(img, region, scale):\n",
    "    return img.reduceRegion(ee.Reducer.sum(), region, scale, maxPixels=1e13)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f43ba7",
   "metadata": {},
   "source": [
    "## 5) Build Weekly Feature Table (server-side → pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c33c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_weekly_features(aoi, start_train, end_train, pred_year):\n",
    "    full_end = f\"{pred_year}-12-31\"\n",
    "    weekly_starts = week_edges(start_train, full_end)\n",
    "\n",
    "    slope_mean = region_mean(slope, aoi, 90).get('slope')\n",
    "    rows = []\n",
    "    for ds in weekly_starts:\n",
    "        d = ee.Date(ds)\n",
    "        start = d\n",
    "        end = d.advance(1, 'week')\n",
    "\n",
    "        fire_img = viirs_week_image(start, end) if USE_VIIRS else firms_modis_week_image(start, end)\n",
    "        fire_sum = region_sum(fire_img, aoi, 375 if USE_VIIRS else 1000).get('fire')\n",
    "\n",
    "        precip = region_mean(chirps_week_sum(start, end), aoi, 5500).get('precip')\n",
    "        ndvi = region_mean(ndvi_week_mean(start, end), aoi, 250).get('ndvi')\n",
    "        lstc = region_mean(lst_week_mean_c(start, end), aoi, 1000).get('lst_c')\n",
    "\n",
    "        feat = ee.Feature(None, {\n",
    "            'date': d.format('YYYY-MM-dd'),\n",
    "            'year': d.get('year'),\n",
    "            'week': d.get('week'),\n",
    "            'viirs_fire_count': fire_sum,\n",
    "            'fire_binary': ee.Number(fire_sum).gt(0),\n",
    "            'precip_mm': precip,\n",
    "            'ndvi': ndvi,\n",
    "            'lst_c': lstc,\n",
    "            'slope_deg': slope_mean\n",
    "        })\n",
    "        rows.append(feat)\n",
    "\n",
    "    fc = ee.FeatureCollection(rows)\n",
    "    return geemap.ee_to_pandas(fc).sort_values('date')\n",
    "\n",
    "df = build_weekly_features(AOI, START_TRAIN, END_TRAIN, PRED_YEAR)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "for c in ['year','week','viirs_fire_count','precip_mm','ndvi','lst_c','slope_deg']:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38045584",
   "metadata": {},
   "source": [
    "## 6) Target & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8538e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if TARGET_MODE == 'count':\n",
    "    df['target'] = df['viirs_fire_count'].fillna(0.0)\n",
    "    df['target_log1p'] = np.log1p(df['target'])\n",
    "    y_col = 'target_log1p'\n",
    "else:\n",
    "    df['target_bin'] = (df['viirs_fire_count'] > 0).astype(int)\n",
    "    y_col = 'target_bin'\n",
    "\n",
    "feature_cols = ['precip_mm', 'ndvi', 'lst_c', 'slope_deg']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(df[feature_cols].values.astype('float32'))\n",
    "df_scaled = df.copy()\n",
    "df_scaled[feature_cols] = X_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fdb921",
   "metadata": {},
   "source": [
    "## 7) Train/Test Split & Sequence Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_mask = df_scaled['date'] <= pd.to_datetime(END_TRAIN)\n",
    "def make_sequences(frame, seq_len, y_column):\n",
    "    Xs, ys, dates = [], [], []\n",
    "    vals = frame[feature_cols].values.astype('float32')\n",
    "    yvals = frame[y_column].values.astype('float32')\n",
    "    for i in range(len(frame) - seq_len):\n",
    "        Xs.append(vals[i:i+seq_len])\n",
    "        ys.append(yvals[i+seq_len])\n",
    "        dates.append(frame.iloc[i+seq_len]['date'])\n",
    "    return np.array(Xs), np.array(ys), dates\n",
    "\n",
    "X_train, y_train, dates_train = make_sequences(df_scaled[train_mask], SEQ_LEN, y_col)\n",
    "X_test,  y_test,  dates_test  = make_sequences(df_scaled[~train_mask], SEQ_LEN, y_col)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a833fb48",
   "metadata": {},
   "source": [
    "## 8) LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f68d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keras.backend.clear_session()\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(SEQ_LEN, len(feature_cols))),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='linear' if TARGET_MODE=='count' else 'sigmoid')\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "              loss='mse' if TARGET_MODE=='count' else 'binary_crossentropy',\n",
    "              metrics=['mae'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test) if len(X_test)>0 else None,\n",
    "                    epochs=50, batch_size=16, verbose=1)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce2b5d",
   "metadata": {},
   "source": [
    "## 9) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74a46b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_test = model.predict(X_test).flatten() if len(X_test)>0 else np.array([])\n",
    "if TARGET_MODE == 'count':\n",
    "    y_test_lin = np.expm1(y_test)\n",
    "    y_pred_lin = np.expm1(y_pred_test)\n",
    "    mae = mean_absolute_error(y_test_lin, y_pred_lin) if len(y_pred_test)>0 else np.nan\n",
    "    rmse = math.sqrt(mean_squared_error(y_test_lin, y_pred_lin)) if len(y_pred_test)>0 else np.nan\n",
    "    r2 = r2_score(y_test_lin, y_pred_lin) if len(y_pred_test)>0 else np.nan\n",
    "else:\n",
    "    mae = mean_absolute_error(y_test, y_pred_test) if len(y_pred_test)>0 else np.nan\n",
    "    rmse = math.sqrt(mean_squared_error(y_test, y_pred_test)) if len(y_pred_test)>0 else np.nan\n",
    "    r2 = r2_score(y_test, y_pred_test) if len(y_pred_test)>0 else np.nan\n",
    "\n",
    "print(f\"MAE: {mae:.3f}, RMSE: {rmse:.3f}, R2: {r2:.3f}\")\n",
    "if len(y_pred_test)>0:\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(dates_test, y_test if TARGET_MODE!='count' else np.expm1(y_test), label='Actual')\n",
    "    plt.plot(dates_test, y_pred_test if TARGET_MODE!='count' else np.expm1(y_pred_test), label='Predicted')\n",
    "    plt.title('Weekly Hotspot Prediction (Test)')\n",
    "    plt.xlabel('Date'); plt.ylabel('Fire count' if TARGET_MODE=='count' else 'Probability')\n",
    "    plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ac8e5",
   "metadata": {},
   "source": [
    "## 10) Forecast 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_2025 = df_scaled[df_scaled['date'].dt.year == PRED_YEAR].copy()\n",
    "def make_sequences_simple(frame, seq_len, y_column):\n",
    "    if len(frame) <= seq_len:\n",
    "        return np.empty((0, seq_len, len(feature_cols))), np.array([]), []\n",
    "    Xs, ys, dates = [], [], []\n",
    "    vals = frame[feature_cols].values.astype('float32')\n",
    "    yvals = frame[y_column].values.astype('float32')\n",
    "    for i in range(len(frame) - seq_len):\n",
    "        Xs.append(vals[i:i+seq_len]); ys.append(yvals[i+seq_len]); dates.append(frame.iloc[i+seq_len]['date'])\n",
    "    return np.array(Xs), np.array(ys), dates\n",
    "\n",
    "X_2025, y_2025, dates_2025 = make_sequences_simple(df_2025, SEQ_LEN, y_col)\n",
    "yhat_2025 = model.predict(X_2025).flatten() if len(X_2025)>0 else np.array([])\n",
    "\n",
    "if TARGET_MODE == 'count':\n",
    "    series = pd.DataFrame({'date': dates_2025, 'pred_fire_count': np.expm1(yhat_2025)})\n",
    "else:\n",
    "    series = pd.DataFrame({'date': dates_2025, 'pred_fire_prob': yhat_2025})\n",
    "\n",
    "series_path = \"/mnt/data/hotspot_2025_predictions.csv\"\n",
    "series.to_csv(series_path, index=False)\n",
    "series.head(), series_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ba3fb",
   "metadata": {},
   "source": [
    "## 11) Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"/mnt/data/lstm_hotspot_model.keras\"\n",
    "scaler_path = \"/mnt/data/feature_scaler.npy\"\n",
    "model.save(model_path)\n",
    "np.save(scaler_path, {'feature_cols': feature_cols,\n",
    "                      'data_min_': getattr(scaler, 'data_min_', None),\n",
    "                      'data_max_': getattr(scaler, 'data_max_', None)})\n",
    "(model_path, scaler_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62162f07",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Notes & References\n",
    "\n",
    "- VIIRS NRT Fires (375m): `ee.ImageCollection(\"NASA/LANCE/SNPP_VIIRS/C2\")`\n",
    "- FIRMS (MODIS) rasterized fires: `ee.ImageCollection(\"FIRMS\")`\n",
    "- CHIRPS Daily precipitation: `ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\")`\n",
    "- MOD13Q1 NDVI v061 (16‑day): `ee.ImageCollection(\"MODIS/061/MOD13Q1\")`\n",
    "- MOD11A2 LST Day v061 (8‑day): `ee.ImageCollection(\"MODIS/061/MOD11A2\")`\n",
    "- SRTM DEM: `ee.Image(\"USGS/SRTMGL1_003\")`\n",
    "- TFRecord with Earth Engine: https://developers.google.com/earth-engine/guides/tfrecord\n",
    "\n",
    "**Extensions**\n",
    "- Switch to `TARGET_MODE='binary'` to predict presence/absence.\n",
    "- Add more predictors: land cover (MCD12Q1), soil moisture (SMAP), wind (ERA5), drought indices.\n",
    "- For pixel/patch‑level modeling and ConvLSTM, export gridded tensors to **TFRecord** and train on image sequences.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}