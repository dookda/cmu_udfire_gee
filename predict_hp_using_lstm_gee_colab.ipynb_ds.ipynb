{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbqHY/BUpp4XQL1/i/xzUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dookda/cmu_udfire_gee/blob/main/predict_hp_using_lstm_gee_colab.ipynb_ds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFmWf1krNU5a"
      },
      "outputs": [],
      "source": [
        "# ติดตั้งไลบรารีที่จำเป็น\n",
        "!pip install geemap folium\n",
        "\n",
        "# นำเข้าไลบรารีที่จำเป็น\n",
        "import ee\n",
        "import geemap\n",
        "import folium\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, Dense, Flatten, Reshape, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# เริ่มต้นใช้งาน GEE\n",
        "ee.Authenticate()\n",
        "try:\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0JSmqzSeNou8",
        "outputId": "5a86d60a-4104-4bca-92aa-d4ffb3d62eea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# กำหนดพื้นที่ศึกษาที่ใหญ่ขึ้น - ครอบคลุมภาคเหนือ\n",
        "STUDY_AREA = ee.Geometry.Polygon(\n",
        "    [[[98.0, 18.0],\n",
        "      [100.0, 18.0],\n",
        "      [100.0, 20.0],\n",
        "      [98.0, 20.0],\n",
        "      [98.0, 18.0]]])  # ขยายเป็น 2° x 2° ≈ 220x220 km\n",
        "\n",
        "# ฟังก์ชันคำนวณ NDVI จาก MOD09Q1\n",
        "def calculate_ndvi(image):\n",
        "    try:\n",
        "        # MOD09Q1 bands: sur_refl_b01 (red), sur_refl_b02 (NIR)\n",
        "        nir = image.select('sur_refl_b02').multiply(0.0001)  # Apply scale factor\n",
        "        red = image.select('sur_refl_b01').multiply(0.0001)  # Apply scale factor\n",
        "\n",
        "        # คำนวณ NDVI\n",
        "        ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
        "\n",
        "        # กำหนดคุณสมบัติให้กับภาพ\n",
        "        return image.addBands(ndvi).copyProperties(image, ['system:time_start'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating NDVI: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันดึงข้อมูล NDVI รายช่วง 8 วันจาก MOD09Q1\n",
        "def get_8day_ndvi(start_date, end_date, study_area):\n",
        "    try:\n",
        "        # เรียกชุดข้อมูล MOD09Q1\n",
        "        modis = ee.ImageCollection('MODIS/061/MOD09Q1') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(study_area)\n",
        "\n",
        "        # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "        size = modis.size().getInfo()\n",
        "        print(f\"จำนวนภาพ MODIS ดิบ: {size}\")\n",
        "        if size == 0:\n",
        "            print(\"ไม่มีข้อมูล MOD09Q1 ในพื้นที่ศึกษา\")\n",
        "            return None\n",
        "\n",
        "        # คำนวณ NDVI\n",
        "        modis_ndvi = modis.map(calculate_ndvi)\n",
        "        print(f\"จำนวนภาพหลังคำนวณ NDVI: {modis_ndvi.size().getInfo()}\")\n",
        "\n",
        "        # เฉลี่ย NDVI เป็นรายช่วง 8 วัน\n",
        "        def create_8day_composite(start_millis):\n",
        "            start = ee.Date(start_millis)\n",
        "            end = start.advance(8, 'day')\n",
        "            composite_collection = modis_ndvi.filterDate(start, end)\n",
        "            count = composite_collection.size()\n",
        "\n",
        "            # สร้างภาพเฉลี่ยและกำหนดคุณสมบัติ\n",
        "            composite_mean = composite_collection.mean() \\\n",
        "                .set('system:time_start', start_millis) \\\n",
        "                .set('system:index', start.format('YYYY_MM_dd'))\n",
        "\n",
        "            # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "            return ee.Algorithms.If(\n",
        "                count.gt(0),\n",
        "                composite_mean,\n",
        "                ee.Image.constant(0).rename('NDVI') \\\n",
        "                    .set('system:time_start', start_millis) \\\n",
        "                    .set('system:index', start.format('YYYY_MM_dd'))\n",
        "            )\n",
        "\n",
        "        # สร้างรายการวันเริ่มต้นของแต่ละช่วง 8 วัน\n",
        "        start_dates = ee.List.sequence(\n",
        "            ee.Date(start_date).millis(),\n",
        "            ee.Date(end_date).millis(),\n",
        "            8 * 24 * 60 * 60 * 1000  # 8 วันในหน่วยมิลลิวินาที\n",
        "        )\n",
        "\n",
        "        # สร้าง ImageCollection\n",
        "        composite_images = start_dates.map(create_8day_composite)\n",
        "        composites_8day = ee.ImageCollection.fromImages(composite_images)\n",
        "\n",
        "        print(f\"จำนวนช่วง 8 วันทั้งหมด: {composites_8day.size().getInfo()}\")\n",
        "\n",
        "        return composites_8day.select('NDVI')\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting 8-day NDVI: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันดึงข้อมูล Hotspot รายช่วง 8 วันจาก FIRMS - แก้ไขให้ดึง T21\n",
        "def get_8day_hotspots(start_date, end_date, study_area):\n",
        "    try:\n",
        "        # เรียกชุดข้อมูล FIRMS\n",
        "        firms = ee.ImageCollection('FIRMS') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(study_area) \\\n",
        "            .select(['T21', 'confidence'])  # เลือกทั้งอุณหภูมิและความเชื่อมั่น\n",
        "\n",
        "        # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "        size = firms.size().getInfo()\n",
        "        print(f\"จำนวนภาพ FIRMS ดิบ: {size}\")\n",
        "        if size == 0:\n",
        "            print(\"ไม่มีข้อมูล FIRMS ในพื้นที่ศึกษา\")\n",
        "            return None\n",
        "\n",
        "        # รวม hotspot เป็นรายช่วง 8 วัน\n",
        "        def create_8day_hotspot_composite(start_millis):\n",
        "            start = ee.Date(start_millis)\n",
        "            end = start.advance(8, 'day')\n",
        "            composite_collection = firms.filterDate(start, end)\n",
        "            count = composite_collection.size()\n",
        "\n",
        "            # คำนวณค่าเฉลี่ย T21 และจำนวน hotspot\n",
        "            composite_mean = composite_collection.mean() \\\n",
        "                .set('system:time_start', start_millis) \\\n",
        "                .set('system:index', start.format('YYYY_MM_dd'))\n",
        "\n",
        "            # เพิ่ม band สำหรับจำนวน hotspot\n",
        "            hotspot_count_band = ee.Image.constant(count).rename('hotspot_count')\n",
        "            composite_with_count = composite_mean.addBands(hotspot_count_band)\n",
        "\n",
        "            return ee.Algorithms.If(\n",
        "                count.gt(0),\n",
        "                composite_with_count,\n",
        "                ee.Image.constant([0, 0]).rename(['T21', 'hotspot_count']) \\\n",
        "                    .set('system:time_start', start_millis) \\\n",
        "                    .set('system:index', start.format('YYYY_MM_dd'))\n",
        "            )\n",
        "\n",
        "        # สร้างรายการวันเริ่มต้นของแต่ละช่วง 8 วัน\n",
        "        start_dates = ee.List.sequence(\n",
        "            ee.Date(start_date).millis(),\n",
        "            ee.Date(end_date).millis(),\n",
        "            8 * 24 * 60 * 60 * 1000  # 8 วันในหน่วยมิลลิวินาที\n",
        "        )\n",
        "\n",
        "        # สร้าง ImageCollection\n",
        "        composite_images = start_dates.map(create_8day_hotspot_composite)\n",
        "        composites_8day = ee.ImageCollection.fromImages(composite_images)\n",
        "\n",
        "        print(f\"จำนวนช่วง 8 วันที่มี hotspot: {composites_8day.size().getInfo()}\")\n",
        "\n",
        "        return composites_8day.select(['T21', 'hotspot_count'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting 8-day hotspots: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันสร้างข้อมูลรวม - แก้ไขให้รวม T21 และ hotspot_count\n",
        "def create_dataset(ndvi_collection, hotspot_collection, study_area):\n",
        "    try:\n",
        "        # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "        if ndvi_collection is None:\n",
        "            print(\"ข้อมูล NDVI เป็น None\")\n",
        "            return None\n",
        "\n",
        "        ndvi_size = ndvi_collection.size().getInfo()\n",
        "        print(f\"NDVI collection size: {ndvi_size}\")\n",
        "\n",
        "        if ndvi_size == 0:\n",
        "            print(\"ไม่มีข้อมูล NDVI\")\n",
        "            return None\n",
        "\n",
        "        # ใช้วันที่ของ NDVI เป็นหลัก\n",
        "        ndvi_times = ndvi_collection.aggregate_array('system:time_start')\n",
        "        print(f\"จำนวนช่วงเวลาที่มีข้อมูล NDVI: {ndvi_times.size().getInfo()}\")\n",
        "\n",
        "        # ฟังก์ชันสำหรับรวมข้อมูลแต่ละช่วง 8 วัน\n",
        "        def combine_8day_data(time_start):\n",
        "            # กรองข้อมูล NDVI ตามเวลา\n",
        "            ndvi_image = ndvi_collection.filter(ee.Filter.eq('system:time_start', time_start)).first()\n",
        "\n",
        "            # หา hotspot ในช่วง 8 วันที่ตรงกับ NDVI\n",
        "            start_date = ee.Date(time_start)\n",
        "            end_date = start_date.advance(8, 'day')\n",
        "\n",
        "            # ดึงข้อมูล FIRMS ในช่วงเวลาเดียวกับ NDVI\n",
        "            firms_in_period = ee.ImageCollection('FIRMS') \\\n",
        "                .filterDate(start_date, end_date) \\\n",
        "                .filterBounds(study_area) \\\n",
        "                .select('T21')\n",
        "\n",
        "            # คำนวณค่าเฉลี่ย T21 และนับจำนวน hotspot\n",
        "            hotspot_count = firms_in_period.size()\n",
        "\n",
        "            # สร้างภาพที่มี hotspot count และ mean T21\n",
        "            mean_t21 = firms_in_period.mean()\n",
        "            hotspot_count_image = ee.Image.constant(hotspot_count).rename('hotspot_count')\n",
        "\n",
        "            # กำหนดค่าเริ่มต้นสำหรับ T21 ถ้าไม่มีข้อมูล\n",
        "            mean_t21_filled = ee.Algorithms.If(\n",
        "                hotspot_count.gt(0),\n",
        "                mean_t21,\n",
        "                ee.Image.constant(0).rename('T21')\n",
        "            )\n",
        "\n",
        "            # รวมภาพ\n",
        "            combined_image = ndvi_image \\\n",
        "                .addBands(ee.Image(mean_t21_filled)) \\\n",
        "                .addBands(hotspot_count_image)\n",
        "\n",
        "            # ลดขนาดข้อมูลเป็นค่าเฉลี่ยของพื้นที่ศึกษา\n",
        "            reduced = combined_image.reduceRegion(\n",
        "                reducer=ee.Reducer.mean(),\n",
        "                geometry=study_area,\n",
        "                scale=1000,  # 1km resolution\n",
        "                maxPixels=1e9\n",
        "            )\n",
        "\n",
        "            # สร้าง Feature พร้อมวันที่\n",
        "            date_str = ee.Date(time_start).format('YYYY-MM-dd')\n",
        "            return ee.Feature(None, reduced.set('date', date_str))\n",
        "\n",
        "        # แปลงเป็น FeatureCollection โดยใช้เวลาของ NDVI\n",
        "        if ndvi_times.size().getInfo() > 0:\n",
        "            combined_fc = ee.FeatureCollection(ndvi_times.map(combine_8day_data))\n",
        "            return combined_fc\n",
        "        else:\n",
        "            print(\"ไม่มีข้อมูล NDVI\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันแปลง FeatureCollection เป็น DataFrame - แก้ไขให้รองรับ T21\n",
        "def fc_to_df(fc):\n",
        "    try:\n",
        "        # ดึงข้อมูลจาก GEE\n",
        "        features = fc.getInfo()['features']\n",
        "    except Exception as e:\n",
        "        print(\"ไม่สามารถดึงข้อมูลจาก GEE ได้:\", str(e))\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # สร้าง dictionary สำหรับเก็บข้อมูล\n",
        "    data_dict = {'date': [], 'NDVI': [], 'T21': [], 'hotspot_count': []}\n",
        "\n",
        "    for feature in features:\n",
        "        props = feature['properties']\n",
        "        if 'NDVI' in props and props['NDVI'] is not None:\n",
        "            data_dict['date'].append(props.get('date', ''))\n",
        "            data_dict['NDVI'].append(props.get('NDVI', 0))\n",
        "            data_dict['T21'].append(props.get('T21', 0))\n",
        "            data_dict['hotspot_count'].append(props.get('hotspot_count', 0))\n",
        "\n",
        "    # สร้าง DataFrame\n",
        "    df = pd.DataFrame(data_dict)\n",
        "\n",
        "    # แปลงคอลัมน์ date เป็น datetime\n",
        "    if not df.empty:\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df.sort_values('date', inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ฟังก์ชันเตรียมข้อมูลสำหรับการฝึกแบบจำลอง - แก้ไขให้ใช้ T21 หรือ hotspot_count ได้\n",
        "def prepare_training_data(df, sequence_length=4, target_column='T21'):\n",
        "    # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "    if df.empty:\n",
        "        raise ValueError(\"ไม่มีข้อมูลใน DataFrame\")\n",
        "\n",
        "    print(f\"จำนวนข้อมูลดิบ: {len(df)}\")\n",
        "    print(f\"คอลัมน์ที่มี: {df.columns.tolist()}\")\n",
        "    print(f\"ตัวอย่างข้อมูล:\\n{df.head()}\")\n",
        "\n",
        "    # ล้างข้อมูลที่ขาดหาย\n",
        "    df_cleaned = df.fillna(0)  # เปลี่ยนจาก dropna() เป็น fillna(0)\n",
        "    print(f\"จำนวนข้อมูลหลังล้าง: {len(df_cleaned)}\")\n",
        "    print(f\"ค่าสถิติพื้นฐาน:\\n{df_cleaned.describe()}\")\n",
        "\n",
        "    # ตรวจสอบว่ามีข้อมูลเพียงพอหลังจากล้างข้อมูล\n",
        "    min_required = sequence_length + 5\n",
        "    if len(df_cleaned) < min_required:\n",
        "        raise ValueError(f\"ข้อมูลไม่เพียงพอสำหรับการสร้างลำดับ ต้องการอย่างน้อย {min_required} ข้อมูล แต่มีเพียง {len(df_cleaned)}\")\n",
        "\n",
        "    # ตรวจสอบคอลัมน์ที่มีอยู่และเลือกเป็น target\n",
        "    available_targets = ['T21', 'hotspot_count']\n",
        "    selected_target = None\n",
        "\n",
        "    for target in available_targets:\n",
        "        if target in df_cleaned.columns:\n",
        "            selected_target = target\n",
        "            print(f\"ใช้ {target} เป็น target variable\")\n",
        "            break\n",
        "\n",
        "    if selected_target is None:\n",
        "        raise ValueError(f\"ไม่พบคอลัมน์ target ใดๆ ในข้อมูล ตรวจสอบคอลัมน์ที่มี: {df_cleaned.columns.tolist()}\")\n",
        "\n",
        "    # เตรียมข้อมูล feature และ target\n",
        "    feature_columns = ['NDVI']\n",
        "    if selected_target == 'T21' and 'hotspot_count' in df_cleaned.columns:\n",
        "        feature_columns.append('hotspot_count')\n",
        "    elif selected_target == 'hotspot_count' and 'T21' in df_cleaned.columns:\n",
        "        feature_columns.append('T21')\n",
        "\n",
        "    X = df_cleaned[feature_columns].values\n",
        "    y = df_cleaned[[selected_target]].values\n",
        "\n",
        "    print(f\"Features ที่ใช้: {feature_columns}\")\n",
        "    print(f\"Target ที่ใช้: {selected_target}\")\n",
        "\n",
        "    # ปรับขนาดข้อมูล\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler_x = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "\n",
        "    X_scaled = scaler_x.fit_transform(X)\n",
        "    y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "    # สร้างลำดับข้อมูลสำหรับ LSTM\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X_scaled) - sequence_length):\n",
        "        X_seq.append(X_scaled[i:i+sequence_length])\n",
        "        y_seq.append(y_scaled[i+sequence_length])\n",
        "\n",
        "    X_seq = np.array(X_seq)\n",
        "    y_seq = np.array(y_seq)\n",
        "\n",
        "    print(f\"จำนวนลำดับที่สร้างได้: {len(X_seq)}\")\n",
        "    print(f\"รูปร่างข้อมูล X: {X_seq.shape}, y: {y_seq.shape}\")\n",
        "\n",
        "    # ไม่ต้อง reshape สำหรับ CNN อีกต่อไป - ใช้รูปร่างปกติสำหรับ LSTM\n",
        "    return X_seq, y_seq, scaler_x, scaler_y\n",
        "\n",
        "# ฟังก์ชันสร้างแบบจำลอง LSTM - เพิ่มฟังก์ชันที่ขาดหาย\n",
        "def create_lstm_model(sequence_length, n_features):\n",
        "    \"\"\"สร้างแบบจำลอง LSTM สำหรับทำนาย hotspot\"\"\"\n",
        "    try:\n",
        "        from tensorflow.keras.models import Sequential\n",
        "        from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "        from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        # LSTM layers\n",
        "        model.add(LSTM(64, return_sequences=True, input_shape=(sequence_length, n_features)))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(LSTM(32, return_sequences=False))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # Output layer\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                      loss='mse',\n",
        "                      metrics=['mae'])\n",
        "\n",
        "        return model\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import TensorFlow ได้ กรุณาติดตั้ง TensorFlow ก่อน\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างแบบจำลอง: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันสร้างแบบจำลอง CNN-LSTM - ปรับปรุงสำหรับข้อมูลที่มีน้อย\n",
        "def create_cnn_lstm_model(sequence_length, n_features):\n",
        "    \"\"\"สร้างแบบจำลอง CNN-LSTM สำหรับทำนาย hotspot\"\"\"\n",
        "    try:\n",
        "        from tensorflow.keras.models import Sequential\n",
        "        from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
        "        from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        # CNN layers - ใช้ Conv1D แทน Conv2D\n",
        "        model.add(Conv1D(filters=32, kernel_size=2, activation='relu',\n",
        "                         input_shape=(sequence_length, n_features)))\n",
        "        model.add(MaxPooling1D(pool_size=2))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # LSTM layers\n",
        "        model.add(LSTM(32, return_sequences=False))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # Output layer\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                      loss='mse',\n",
        "                      metrics=['mae'])\n",
        "\n",
        "        return model\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import TensorFlow ได้ กรุณาติดตั้ง TensorFlow ก่อน\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างแบบจำลอง CNN-LSTM: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันประเมินผลแบบจำลอง\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'MAE: {mae:.4f}')\n",
        "    print(f'R²: {r2:.4f}')\n",
        "\n",
        "    return mse, mae, r2\n",
        "\n",
        "# ฟังก์ชันทำนาย hotspot สำหรับช่วง 8 วันถัดไป\n",
        "def predict_next_8days(model, last_sequence, scaler_x, scaler_y):\n",
        "    # ทำนาย\n",
        "    prediction_scaled = model.predict(last_sequence)\n",
        "\n",
        "    # แปลงกลับเป็นค่าปกติ\n",
        "    prediction = scaler_y.inverse_transform(prediction_scaled)\n",
        "\n",
        "    return prediction[0][0]\n",
        "\n",
        "# ฟังก์ชันสร้างแผนที่ Folium\n",
        "def create_prediction_map(prediction, study_area, date):\n",
        "    try:\n",
        "        import folium\n",
        "\n",
        "        # สร้างแผนที่\n",
        "        map_center = study_area.centroid().coordinates().getInfo()[::-1]\n",
        "        m = folium.Map(location=map_center, zoom_start=10)\n",
        "\n",
        "        # เพิ่ม layer พื้นที่ศึกษา\n",
        "        study_area_geo = study_area.getInfo()\n",
        "        folium.GeoJson(\n",
        "            study_area_geo,\n",
        "            name='Study Area',\n",
        "            style_function=lambda x: {'fillColor': 'blue', 'color': 'blue', 'weight': 2, 'fillOpacity': 0.1}\n",
        "        ).add_to(m)\n",
        "\n",
        "        # เพิ่มข้อความทำนาย\n",
        "        prediction_text = f'Predicted Value for next 8 days ({date}): {prediction:.2f}'\n",
        "        folium.Marker(\n",
        "            location=map_center,\n",
        "            icon=folium.DivIcon(\n",
        "                html=f'<div style=\"font-size: 16pt; color: red; background-color: white; padding: 5px; border-radius: 5px;\">{prediction_text}</div>'\n",
        "            )\n",
        "        ).add_to(m)\n",
        "\n",
        "        return m\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import folium ได้ กรุณาติดตั้ง folium ก่อน\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างแผนที่: {e}\")\n",
        "        return None\n",
        "\n",
        "# รันโค้ดหลัก\n",
        "def main():\n",
        "    import ee\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    # Initialize Earth Engine (ต้องทำการ authenticate ก่อน)\n",
        "    # ee.Authenticate()  # ถ้ายังไม่ได้ authenticate\n",
        "    # ee.Initialize()\n",
        "\n",
        "    # กำหนดช่วงเวลาข้อมูล\n",
        "    start_date = '2018-01-01'\n",
        "    end_date = '2024-06-01'\n",
        "\n",
        "    print(\"กำลังดึงข้อมูล NDVI รายช่วง 8 วัน...\")\n",
        "    ndvi_data = get_8day_ndvi(start_date, end_date, STUDY_AREA)\n",
        "\n",
        "    if ndvi_data is None:\n",
        "        print(\"ไม่สามารถดึงข้อมูล NDVI ได้\")\n",
        "        # ขยายพื้นที่ศึกษา\n",
        "        STUDY_AREA_EXPANDED = ee.Geometry.Polygon(\n",
        "            [[[98.0, 18.0],\n",
        "              [99.5, 18.0],\n",
        "              [99.5, 19.5],\n",
        "              [98.0, 19.5],\n",
        "              [98.0, 18.0]]])\n",
        "        print(\"ขยายพื้นที่ศึกษา\")\n",
        "        ndvi_data = get_8day_ndvi(start_date, end_date, STUDY_AREA_EXPANDED)\n",
        "        study_area = STUDY_AREA_EXPANDED\n",
        "    else:\n",
        "        study_area = STUDY_AREA\n",
        "\n",
        "    if ndvi_data is not None:\n",
        "        print(f\"จำนวนช่วง 8 วันที่มีข้อมูล NDVI: {ndvi_data.size().getInfo()}\")\n",
        "\n",
        "        print(\"กำลังสร้างชุดข้อมูล...\")\n",
        "        dataset = create_dataset(ndvi_data, None, study_area)  # ไม่ใช้ hotspot_data แยก\n",
        "\n",
        "        if dataset is not None:\n",
        "            print(\"กำลังแปลงข้อมูลเป็น DataFrame...\")\n",
        "            df = fc_to_df(dataset)\n",
        "            print(f\"จำนวนข้อมูลใน DataFrame: {len(df)}\")\n",
        "\n",
        "            if not df.empty and len(df) > 10:\n",
        "                print(\"ตัวอย่างข้อมูล:\")\n",
        "                print(df.head())\n",
        "\n",
        "                print(\"กำลังเตรียมข้อมูลสำหรับการฝึก...\")\n",
        "                try:\n",
        "                    X, y, scaler_x, scaler_y = prepare_training_data(df, sequence_length=4)\n",
        "                    print(f\"ข้อมูลที่เตรียม: X.shape = {X.shape}, y.shape = {y.shape}\")\n",
        "\n",
        "                    # แบ่งข้อมูลฝึกและทดสอบ\n",
        "                    split_idx = int(len(X) * 0.8)\n",
        "                    X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "                    y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "                    print(f\"ข้อมูลฝึก: {X_train.shape}, ข้อมูลทดสอบ: {X_test.shape}\")\n",
        "\n",
        "                    # สร้างและฝึกแบบจำลอง\n",
        "                    print(\"กำลังสร้างแบบจำลอง...\")\n",
        "                    # ใช้ LSTM model\n",
        "                    model = create_lstm_model(X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "                    if model is None:\n",
        "                        print(\"ไม่สามารถสร้างแบบจำลองได้ กรุณาตรวจสอบการติดตั้ง TensorFlow\")\n",
        "                        return\n",
        "\n",
        "                    # หรือใช้ CNN-LSTM model\n",
        "                    # model = create_cnn_lstm_model(X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "                    print(\"กำลังฝึกแบบจำลอง...\")\n",
        "                    history = model.fit(\n",
        "                        X_train, y_train,\n",
        "                        epochs=50,\n",
        "                        batch_size=8,  # ลด batch size\n",
        "                        validation_data=(X_test, y_test) if len(X_test) > 0 else None,\n",
        "                        verbose=1\n",
        "                    )\n",
        "\n",
        "                    # ประเมินแบบจำลอง\n",
        "                    if len(X_test) > 0:\n",
        "                        print(\"กำลังประเมินแบบจำลอง...\")\n",
        "                        y_pred = model.predict(X_test)\n",
        "                        y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n",
        "                        y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "                        print(\"ผลการประเมินแบบจำลอง:\")\n",
        "                        evaluate_model(y_test_rescaled, y_pred_rescaled)\n",
        "\n",
        "                    # ทำนายช่วง 8 วันถัดไป\n",
        "                    last_sequence = X[-1:]\n",
        "                    next_8days_prediction = predict_next_8days(model, last_sequence, scaler_x, scaler_y)\n",
        "\n",
        "                    # แสดงผลการทำนาย\n",
        "                    from datetime import datetime, timedelta\n",
        "                    next_8days_date = (datetime.now() + timedelta(days=8)).strftime('%Y-%m-%d')\n",
        "                    print(f\"ทำนายสำหรับช่วง 8 วันถัดไป ({next_8days_date}): {next_8days_prediction:.2f}\")\n",
        "\n",
        "                    # สร้างแผนที่แสดงผล\n",
        "                    print(\"กำลังสร้างแผนที่...\")\n",
        "                    try:\n",
        "                        prediction_map = create_prediction_map(next_8days_prediction, study_area, next_8days_date)\n",
        "                        if prediction_map is not None:\n",
        "                            prediction_map.save('hotspot_prediction_map_8day.html')\n",
        "                            print(\"บันทึกแผนที่เรียบร้อยแล้ว: hotspot_prediction_map_8day.html\")\n",
        "                        else:\n",
        "                            print(\"ไม่สามารถสร้างแผนที่ได้\")\n",
        "                    except Exception as map_error:\n",
        "                        print(f\"ไม่สามารถสร้างแผนที่ได้: {map_error}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"เกิดข้อผิดพลาดในการเตรียมข้อมูล: {e}\")\n",
        "            else:\n",
        "                print(\"ข้อมูลไม่เพียงพอสำหรับการสร้างแบบจำลอง\")\n",
        "        else:\n",
        "            print(\"ไม่สามารถสร้างชุดข้อมูลได้\")\n",
        "    else:\n",
        "        print(\"ไม่สามารถดึงข้อมูล NDVI ได้\")\n",
        "\n",
        "# เรียกใช้ฟังก์ชันหลัก\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pwlCEijk_EKZ",
        "outputId": "36aaf5e6-63b1-41f1-9163-5ed8a78ff88a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "กำลังดึงข้อมูล NDVI รายช่วง 8 วัน...\n",
            "จำนวนภาพ MODIS ดิบ: 295\n",
            "จำนวนภาพหลังคำนวณ NDVI: 295\n",
            "จำนวนช่วง 8 วันทั้งหมด: 293\n",
            "จำนวนช่วง 8 วันที่มีข้อมูล NDVI: 293\n",
            "กำลังสร้างชุดข้อมูล...\n",
            "NDVI collection size: 293\n",
            "จำนวนช่วงเวลาที่มีข้อมูล NDVI: 293\n",
            "กำลังแปลงข้อมูลเป็น DataFrame...\n",
            "จำนวนข้อมูลใน DataFrame: 292\n",
            "ตัวอย่างข้อมูล:\n",
            "        date      NDVI         T21  hotspot_count\n",
            "0 2018-01-01  0.429640         NaN              8\n",
            "1 2018-01-09  0.711561  311.446213              8\n",
            "2 2018-01-17  0.733592  315.999317              8\n",
            "3 2018-01-25  0.712856  319.502396              8\n",
            "4 2018-02-02  0.667996  315.940881              8\n",
            "กำลังเตรียมข้อมูลสำหรับการฝึก...\n",
            "จำนวนข้อมูลดิบ: 292\n",
            "คอลัมน์ที่มี: ['date', 'NDVI', 'T21', 'hotspot_count']\n",
            "ตัวอย่างข้อมูล:\n",
            "        date      NDVI         T21  hotspot_count\n",
            "0 2018-01-01  0.429640         NaN              8\n",
            "1 2018-01-09  0.711561  311.446213              8\n",
            "2 2018-01-17  0.733592  315.999317              8\n",
            "3 2018-01-25  0.712856  319.502396              8\n",
            "4 2018-02-02  0.667996  315.940881              8\n",
            "จำนวนข้อมูลหลังล้าง: 292\n",
            "ค่าสถิติพื้นฐาน:\n",
            "                                date        NDVI         T21  hotspot_count\n",
            "count                            292  292.000000  292.000000     292.000000\n",
            "mean   2021-03-12 00:39:27.123287552    0.575006  253.549926       7.993151\n",
            "min              2018-01-01 00:00:00    0.000000    0.000000       6.000000\n",
            "25%              2019-08-06 00:00:00    0.519160  311.127939       8.000000\n",
            "50%              2021-03-10 00:00:00    0.594482  316.269211       8.000000\n",
            "75%              2022-10-21 00:00:00    0.673770  319.776603       8.000000\n",
            "max              2024-05-25 00:00:00    0.800639  331.990759       8.000000\n",
            "std                              NaN    0.135822  127.870983       0.117041\n",
            "ใช้ T21 เป็น target variable\n",
            "Features ที่ใช้: ['NDVI', 'hotspot_count']\n",
            "Target ที่ใช้: T21\n",
            "จำนวนลำดับที่สร้างได้: 288\n",
            "รูปร่างข้อมูล X: (288, 4, 2), y: (288, 1)\n",
            "ข้อมูลที่เตรียม: X.shape = (288, 4, 2), y.shape = (288, 1)\n",
            "ข้อมูลฝึก: (230, 4, 2), ข้อมูลทดสอบ: (58, 4, 2)\n",
            "กำลังสร้างแบบจำลอง...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "กำลังฝึกแบบจำลอง...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.8955 - mae: 0.7450 - val_loss: 0.6709 - val_mae: 0.6360\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9863 - mae: 0.7677 - val_loss: 0.6915 - val_mae: 0.6557\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7397 - mae: 0.6409 - val_loss: 0.6721 - val_mae: 0.6265\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8185 - mae: 0.6803 - val_loss: 0.6811 - val_mae: 0.6353\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7526 - mae: 0.6381 - val_loss: 0.6751 - val_mae: 0.6309\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8605 - mae: 0.7040 - val_loss: 0.6791 - val_mae: 0.6327\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.6661 - mae: 0.6008 - val_loss: 0.6847 - val_mae: 0.6360\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.7312 - mae: 0.6313 - val_loss: 0.6784 - val_mae: 0.6305\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.8107 - mae: 0.6676 - val_loss: 0.6850 - val_mae: 0.6368\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.7592 - mae: 0.6261 - val_loss: 0.6802 - val_mae: 0.6288\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.9044 - mae: 0.7214 - val_loss: 0.6932 - val_mae: 0.6407\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7115 - mae: 0.6160 - val_loss: 0.6716 - val_mae: 0.6197\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8904 - mae: 0.7048 - val_loss: 0.6838 - val_mae: 0.6348\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.6986 - mae: 0.6078 - val_loss: 0.6815 - val_mae: 0.6259\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8033 - mae: 0.6540 - val_loss: 0.6783 - val_mae: 0.6268\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7787 - mae: 0.6299 - val_loss: 0.6738 - val_mae: 0.6184\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6610 - mae: 0.5772 - val_loss: 0.6850 - val_mae: 0.6331\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7733 - mae: 0.6503 - val_loss: 0.6826 - val_mae: 0.6348\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7524 - mae: 0.6514 - val_loss: 0.6873 - val_mae: 0.6337\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8819 - mae: 0.7142 - val_loss: 0.7010 - val_mae: 0.6458\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.6972 - mae: 0.6123 - val_loss: 0.6906 - val_mae: 0.6312\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6787 - mae: 0.6135 - val_loss: 0.6909 - val_mae: 0.6279\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7669 - mae: 0.6320 - val_loss: 0.6891 - val_mae: 0.6287\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7563 - mae: 0.6432 - val_loss: 0.6992 - val_mae: 0.6312\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6991 - mae: 0.6136 - val_loss: 0.6915 - val_mae: 0.6256\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.7282 - mae: 0.6281 - val_loss: 0.6833 - val_mae: 0.6233\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8288 - mae: 0.6638 - val_loss: 0.6894 - val_mae: 0.6347\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7322 - mae: 0.6296 - val_loss: 0.6925 - val_mae: 0.6250\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7348 - mae: 0.6355 - val_loss: 0.7031 - val_mae: 0.6307\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7953 - mae: 0.6786 - val_loss: 0.6936 - val_mae: 0.6276\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7682 - mae: 0.6531 - val_loss: 0.6993 - val_mae: 0.6327\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8007 - mae: 0.6574 - val_loss: 0.6840 - val_mae: 0.6220\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.7956 - mae: 0.6508 - val_loss: 0.6905 - val_mae: 0.6275\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.7757 - mae: 0.6389 - val_loss: 0.6918 - val_mae: 0.6239\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.7168 - mae: 0.6176 - val_loss: 0.6924 - val_mae: 0.6249\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.6897 - mae: 0.5989 - val_loss: 0.6890 - val_mae: 0.6237\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8343 - mae: 0.6818 - val_loss: 0.7029 - val_mae: 0.6320\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7037 - mae: 0.6105 - val_loss: 0.6911 - val_mae: 0.6174\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8362 - mae: 0.6672 - val_loss: 0.7023 - val_mae: 0.6261\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8112 - mae: 0.6580 - val_loss: 0.7197 - val_mae: 0.6384\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8079 - mae: 0.6674 - val_loss: 0.6942 - val_mae: 0.6207\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7515 - mae: 0.6186 - val_loss: 0.6915 - val_mae: 0.6138\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.6721 - mae: 0.5863 - val_loss: 0.6707 - val_mae: 0.5968\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7058 - mae: 0.6001 - val_loss: 0.6901 - val_mae: 0.6161\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7271 - mae: 0.6276 - val_loss: 0.6858 - val_mae: 0.6150\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.8772 - mae: 0.7163 - val_loss: 0.6765 - val_mae: 0.6030\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.8957 - mae: 0.6976 - val_loss: 0.6990 - val_mae: 0.6239\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.7091 - mae: 0.6128 - val_loss: 0.6766 - val_mae: 0.6021\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.7766 - mae: 0.6427 - val_loss: 0.6779 - val_mae: 0.6014\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7479 - mae: 0.6249 - val_loss: 0.6785 - val_mae: 0.6037\n",
            "กำลังประเมินแบบจำลอง...\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step\n",
            "ผลการประเมินแบบจำลอง:\n",
            "MSE: 11056.0097\n",
            "MAE: 77.0649\n",
            "R²: 0.0818\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "ทำนายสำหรับช่วง 8 วันถัดไป (2025-09-02): 266.11\n",
            "กำลังสร้างแผนที่...\n",
            "บันทึกแผนที่เรียบร้อยแล้ว: hotspot_prediction_map_8day.html\n"
          ]
        }
      ]
    }
  ]
}