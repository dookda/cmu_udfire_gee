{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPXzUaGgMr/p1OWnfFbBWB/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dookda/cmu_udfire_gee/blob/main/predict_hp_using_lstm_gee_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U geemap\n",
        "\n",
        "# !pip -q install -U geemap earthengine-api pandas numpy scikit-learn tensorflow geopandas shapely rasterio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOsVz4UU6eMi",
        "outputId": "59ccb438-b935-44c0-dc5a-1fc6499c2a81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/631.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.5/631.5 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bmZFoFA04uQI"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import folium\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import ee, geemap, time\n",
        "from datetime import datetime\n",
        "\n",
        "ee.Authenticate()\n",
        "try:\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import geemap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from datetime import datetime, timedelta\n",
        "import folium\n",
        "from folium.raster_layers import ImageOverlay\n",
        "from PIL import Image\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Authenticate and initialize Earth Engine (run this once)\n",
        "# ee.Authenticate()\n",
        "ee.Authenticate()\n",
        "try:\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")"
      ],
      "metadata": {
        "id": "nfaV6MsBKx3C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the area of interest (approximate bounding box for Tambon Suthep)\n",
        "min_lon = 98.89\n",
        "min_lat = 18.77\n",
        "max_lon = 98.98\n",
        "max_lat = 18.82\n",
        "aoi = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])\n",
        "\n",
        "# MODIS collection for fire data\n",
        "collection = ee.ImageCollection('MODIS/061/MOD14A1') \\\n",
        "    .filterDate('2020-01-01', '2024-12-31') \\\n",
        "    .filterBounds(aoi)\n",
        "\n",
        "# Function to create weekly composites (max fire mask)\n",
        "def weekly_composite(start_date):\n",
        "    start = ee.Date(start_date)\n",
        "    end = start.advance(7, 'day')\n",
        "    weekly_coll = collection.filterDate(start, end)\n",
        "\n",
        "    # Check if the collection is empty\n",
        "    count = weekly_coll.size().getInfo()\n",
        "    if count == 0:\n",
        "        print(f\"No data for week starting {start_date}, returning zero image\")\n",
        "        return ee.Image.constant(0).rename('FireMask').clip(aoi).reproject(crs='EPSG:4326', scale=1000)\n",
        "\n",
        "    weekly = weekly_coll.max()\n",
        "    # Check if the image has the FireMask band\n",
        "    band_names = weekly.bandNames().getInfo()\n",
        "    if 'FireMask' not in band_names:\n",
        "        print(f\"No FireMask band for week starting {start_date}, returning zero image\")\n",
        "        return ee.Image.constant(0).rename('FireMask').clip(aoi).reproject(crs='EPSG:4326', scale=1000)\n",
        "\n",
        "    weekly = weekly.select('FireMask').clip(aoi).reproject(crs='EPSG:4326', scale=1000)\n",
        "    # Mask fire: 1 if fire (FireMask >=7), 0 otherwise\n",
        "    fire = weekly.gte(7)\n",
        "    return fire.set('system:time_start', start.millis())\n",
        "\n",
        "# Generate list of start dates for weeks from 2020 to 2024\n",
        "start_date = datetime(2020, 1, 1)\n",
        "end_date = datetime(2024, 12, 31)\n",
        "weekly_dates = []\n",
        "current = start_date\n",
        "while current < end_date:\n",
        "    weekly_dates.append(current.strftime('%Y-%m-%d'))\n",
        "    current += timedelta(days=7)\n",
        "\n",
        "# Create weekly image collection (server-side)\n",
        "weekly_images = [weekly_composite(date) for date in weekly_dates]\n",
        "weekly_collection = ee.ImageCollection.fromImages(weekly_images)\n",
        "\n",
        "# Get spatial dimensions (approximate, based on 1km resolution)\n",
        "scale = 1000  # 1km in meters\n",
        "dx = (max_lon - min_lon) / (scale / 111000)  # Approx 1 deg = 111km\n",
        "dy = (max_lat - min_lat) / (scale / 111000)\n",
        "ncols = int(np.ceil((max_lon - min_lon) / dx))\n",
        "nrows = int(np.ceil((max_lat - min_lat) / dy))\n",
        "\n",
        "# Download all weekly data as numpy arrays\n",
        "data = []\n",
        "image_list = weekly_collection.toList(weekly_collection.size())\n",
        "for i in range(len(weekly_dates)):\n",
        "    try:\n",
        "        image = ee.Image(image_list.get(i))\n",
        "        # Use date as a fallback identifier for logging\n",
        "        img_id = weekly_dates[i]\n",
        "        array = geemap.ee_to_numpy(image, region=aoi, scale=1000)\n",
        "        if array is not None and array.shape[0] > 0 and array.shape[1] > 0:\n",
        "            data.append(array[:, :, 0])  # Single band (FireMask)\n",
        "        else:\n",
        "            print(f\"Warning: Empty array for week {img_id}, using zero array\")\n",
        "            data.append(np.zeros((nrows, ncols)))\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing week {img_id}: {str(e)}\")\n",
        "        data.append(np.zeros((nrows, ncols)))\n",
        "\n",
        "# Ensure consistent shape\n",
        "data = [d[:nrows, :ncols] for d in data if d.shape == (nrows, ncols)]\n",
        "if len(data) == 0:\n",
        "    raise ValueError(\"No valid data retrieved. Check MODIS data availability or AOI.\")\n",
        "data = np.stack(data, axis=0)  # Shape: (time, height, width)\n",
        "\n",
        "# Data preparation for CNN-LSTM\n",
        "seq_length = 4\n",
        "X, y = [], []\n",
        "for i in range(len(data) - seq_length):\n",
        "    X.append(data[i:i+seq_length])\n",
        "    y.append(data[i+seq_length])\n",
        "X = np.array(X)  # Shape: (samples, seq, h, w)\n",
        "y = np.array(y)  # Shape: (samples, h, w)\n",
        "X = np.expand_dims(X, axis=-1)  # Add channel: (samples, seq, h, w, 1)\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dataset\n",
        "class FireDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_ds = FireDataset(X_train, y_train)\n",
        "test_ds = FireDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=8)\n",
        "\n",
        "# CNN-LSTM Model\n",
        "class CNNLSTM(nn.Module):\n",
        "    def __init__(self, height, width):\n",
        "        super(CNNLSTM, self).__init__()\n",
        "        self.conv = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=(seq_length, 3, 3), padding=(0, 1, 1))\n",
        "        self.pool = nn.MaxPool3d((1, 2, 2))\n",
        "        conv_output_size = 16 * (height // 2) * (width // 2)\n",
        "        self.lstm = nn.LSTM(input_size=conv_output_size, hidden_size=128, num_layers=1, batch_first=True)\n",
        "        self.fc = nn.Linear(128, height * width)\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 4, 1, 2, 3)  # (batch, seq, h, w, ch) -> (batch, ch, seq, h, w)\n",
        "        x = self.conv(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x, _ = self.lstm(x.unsqueeze(1))\n",
        "        x = self.fc(x.squeeze(1))\n",
        "        x = torch.sigmoid(x)  # Binary output\n",
        "        return x.view(-1, self.height, self.width)\n",
        "\n",
        "model = CNNLSTM(nrows, ncols)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluate\n",
        "model.eval()\n",
        "y_pred = []\n",
        "y_true = []\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        pred = (outputs > 0.5).float()\n",
        "        y_pred.append(pred.numpy().flatten())\n",
        "        y_true.append(targets.numpy().flatten())\n",
        "\n",
        "y_pred = np.concatenate(y_pred)\n",
        "y_true = np.concatenate(y_true)\n",
        "\n",
        "# Evaluation metrics\n",
        "print('Accuracy:', accuracy_score(y_true, y_pred))\n",
        "print('Precision:', precision_score(y_true, y_pred, average='macro', zero_division=0))\n",
        "print('Recall:', recall_score(y_true, y_pred, average='macro', zero_division=0))\n",
        "print('F1:', f1_score(y_true, y_pred, average='macro', zero_division=0))\n",
        "\n",
        "# Predict next week\n",
        "last_seq = data[-seq_length:]  # Last 4 weeks\n",
        "last_seq = np.expand_dims(last_seq, axis=(0, -1))  # Shape: (1, seq, h, w, 1)\n",
        "last_seq = torch.tensor(last_seq, dtype=torch.float32)\n",
        "with torch.no_grad():\n",
        "    next_pred = model(last_seq)\n",
        "    next_pred = (next_pred > 0.5).float().squeeze().numpy()  # Shape: (h, w)\n",
        "\n",
        "# Create Folium map\n",
        "m = folium.Map(location=[(min_lat + max_lat)/2, (min_lon + max_lon)/2], zoom_start=13)\n",
        "\n",
        "# Create image from prediction (binary, black/white)\n",
        "pred_img = (next_pred * 255).astype(np.uint8)\n",
        "img = Image.fromarray(pred_img, mode='L')\n",
        "img_data = io.BytesIO()\n",
        "img.save(img_data, 'PNG')\n",
        "img_data.seek(0)\n",
        "\n",
        "# Bounds for overlay\n",
        "bounds = [[min_lat, min_lon], [max_lat, max_lon]]\n",
        "\n",
        "ImageOverlay(\n",
        "    image=img_data,\n",
        "    bounds=bounds,\n",
        "    opacity=0.6,\n",
        ").add_to(m)\n",
        "\n",
        "# Save or display map\n",
        "# m.save('next_week_hotspot_prediction.html')\n",
        "# print('Folium map saved as next_week_hotspot_prediction.html')\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "7pz2crHh-0vB",
        "outputId": "8e4d6bbf-c0bb-44e5-a996-99b237587f45"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No data for week starting 2022-10-12, returning zero image\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No valid data retrieved. Check MODIS data availability or AOI.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4272712681.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No valid data retrieved. Check MODIS data availability or AOI.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (time, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No valid data retrieved. Check MODIS data availability or AOI."
          ]
        }
      ]
    }
  ]
}