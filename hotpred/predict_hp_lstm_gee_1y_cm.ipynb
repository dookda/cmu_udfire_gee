{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dookda/cmu_udfire_gee/blob/main/hotpred/predict_hp_lstm_gee_1y_cm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0c0ebe11",
      "metadata": {
        "id": "0c0ebe11"
      },
      "outputs": [],
      "source": [
        "# เริ่มต้นใช้งาน GEE\n",
        "import ee\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import calendar\n",
        "\n",
        "ee.Authenticate()\n",
        "try:\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")\n",
        "except Exception as e:\n",
        "    ee.Authenticate()\n",
        "    ee.Initialize(project=\"ee-sakda-451407\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7167956a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7167956a",
        "outputId": "ef51b2ec-e13a-44c3-d97f-36e6aa5b4cbe"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "\n",
        "# กำหนดพื้นที่ศึกษา เชียงใหม่\n",
        "# siteName = 'Mae Hong Son'\n",
        "siteName = 'Chiang Mai'\n",
        "# siteName = 'Nan'\n",
        "# siteName = 'Uttaradit'\n",
        "study_area = ee.FeatureCollection(\"FAO/GAUL/2015/level1\").filter(ee.Filter.eq('ADM0_NAME', 'Thailand')).filter(ee.Filter.eq('ADM1_NAME', siteName))\n",
        "\n",
        "# config figure height\n",
        "f = folium.Figure(height=300)\n",
        "\n",
        "# add map to figure\n",
        "m = folium.Map(location=[18.9, 99.0], zoom_start=7).add_to(f)\n",
        "\n",
        "# add study area to map\n",
        "folium.GeoJson(study_area.getInfo()).add_to(m)\n",
        "\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "020b827e",
      "metadata": {
        "id": "020b827e"
      },
      "outputs": [],
      "source": [
        "# ฟังก์ชันคำนวณ NDVI จาก MOD09Q1\n",
        "def calculate_ndvi(image):\n",
        "    try:\n",
        "        # MOD09Q1 bands: sur_refl_b01 (red), sur_refl_b02 (NIR)\n",
        "        nir = image.select('sur_refl_b02').multiply(0.0001)  # Apply scale factor\n",
        "        red = image.select('sur_refl_b01').multiply(0.0001)  # Apply scale factor\n",
        "\n",
        "        # คำนวณ NDVI\n",
        "        ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
        "\n",
        "        # กำหนดคุณสมบัติให้กับภาพ\n",
        "        return image.addBands(ndvi).copyProperties(image, ['system:time_start'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating NDVI: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันดึงข้อมูล NDVI รายเดือนจาก MOD09Q1\n",
        "def get_monthly_ndvi(start_date, end_date, study_area):\n",
        "    try:\n",
        "        # เรียกชุดข้อมูล MOD09Q1\n",
        "        modis = ee.ImageCollection('MODIS/061/MOD09Q1') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(study_area)\n",
        "\n",
        "        # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "        size = modis.size().getInfo()\n",
        "        print(f\"จำนวนภาพ MODIS ดิบ: {size}\")\n",
        "        if size == 0:\n",
        "            print(\"ไม่มีข้อมูล MOD09Q1 ในพื้นที่ศึกษา\")\n",
        "            return None\n",
        "\n",
        "        # คำนวณ NDVI\n",
        "        modis_ndvi = modis.map(calculate_ndvi)\n",
        "        print(f\"จำนวนภาพหลังคำนวณ NDVI: {modis_ndvi.size().getInfo()}\")\n",
        "\n",
        "        # เฉลี่ย NDVI เป็นรายเดือน\n",
        "        def create_monthly_composite(year_month):\n",
        "            year = ee.Number(year_month).divide(100).floor().int()\n",
        "            month = ee.Number(year_month).mod(100).int()\n",
        "\n",
        "            start = ee.Date.fromYMD(year, month, 1)\n",
        "            end = start.advance(1, 'month')\n",
        "\n",
        "            monthly_collection = modis_ndvi.filterDate(start, end)\n",
        "            count = monthly_collection.size()\n",
        "\n",
        "            # สร้างภาพเฉลี่ยรายเดือน\n",
        "            monthly_mean = monthly_collection.mean() \\\n",
        "                .set('system:time_start', start.millis()) \\\n",
        "                .set('system:index', start.format('YYYY_MM')) \\\n",
        "                .set('year', year) \\\n",
        "                .set('month', month)\n",
        "\n",
        "            return ee.Algorithms.If(\n",
        "                count.gt(0),\n",
        "                monthly_mean,\n",
        "                ee.Image.constant(0).rename('NDVI') \\\n",
        "                    .set('system:time_start', start.millis()) \\\n",
        "                    .set('system:index', start.format('YYYY_MM')) \\\n",
        "                    .set('year', year) \\\n",
        "                    .set('month', month)\n",
        "            )\n",
        "\n",
        "        # สร้างรายการปี-เดือน\n",
        "        start_year = int(start_date.split('-')[0])\n",
        "        end_year = int(end_date.split('-')[0])\n",
        "        year_months = []\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            start_month = 1 if year > start_year else int(start_date.split('-')[1])\n",
        "            end_month = 12 if year < end_year else int(end_date.split('-')[1])\n",
        "\n",
        "            for month in range(start_month, end_month + 1):\n",
        "                year_months.append(year * 100 + month)\n",
        "\n",
        "        year_months_ee = ee.List(year_months)\n",
        "\n",
        "        # สร้าง ImageCollection\n",
        "        monthly_images = year_months_ee.map(create_monthly_composite)\n",
        "        monthly_composites = ee.ImageCollection.fromImages(monthly_images)\n",
        "\n",
        "        print(f\"จำนวนเดือนทั้งหมด: {monthly_composites.size().getInfo()}\")\n",
        "\n",
        "        return monthly_composites.select('NDVI')\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting monthly NDVI: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันดึงข้อมูล Hotspot รายเดือนจาก FIRMS - MODIFIED VERSION\n",
        "def get_monthly_hotspots(start_date, end_date, study_area):\n",
        "    try:\n",
        "        # เรียกชุดข้อมูล FIRMS\n",
        "        firms = ee.ImageCollection('FIRMS') \\\n",
        "            .filterDate(start_date, end_date) \\\n",
        "            .filterBounds(study_area)\n",
        "\n",
        "        # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "        size = firms.size().getInfo()\n",
        "        print(f\"จำนวนภาพ FIRMS ดิบ: {size}\")\n",
        "        if size == 0:\n",
        "            print(\"ไม่มีข้อมูล FIRMS ในพื้นที่ศึกษา\")\n",
        "            return None\n",
        "\n",
        "        # 1. Assign T21 value to 1 for each layer (convert to hotspot presence/absence)\n",
        "        def convert_to_presence(image):\n",
        "            # Create binary hotspot mask where T21 > 0 (presence of hotspot)\n",
        "            hotspot_presence = image.select('T21').gt(0).rename('hotspot_presence')\n",
        "            return image.addBands(hotspot_presence).copyProperties(image, ['system:time_start'])\n",
        "\n",
        "        firms_with_presence = firms.map(convert_to_presence)\n",
        "\n",
        "        # รวม hotspot เป็นรายเดือนใหม่\n",
        "        def create_monthly_hotspot_composite(year_month):\n",
        "            year = ee.Number(year_month).divide(100).floor().int()\n",
        "            month = ee.Number(year_month).mod(100).int()\n",
        "\n",
        "            start = ee.Date.fromYMD(year, month, 1)\n",
        "            end = start.advance(1, 'month')\n",
        "\n",
        "            monthly_collection = firms_with_presence.filterDate(start, end)\n",
        "            count = monthly_collection.size()\n",
        "\n",
        "            # 2. Use spatial reduce to sum new value for study area\n",
        "            # 3. Sum hotspot for month with time series reduce\n",
        "            if count.getInfo() > 0:\n",
        "                # Sum hotspot presence across time for the month\n",
        "                monthly_sum = monthly_collection.select('hotspot_presence').sum()\n",
        "\n",
        "                # Reduce spatially to get total hotspot count for the study area\n",
        "                hotspot_count = monthly_sum.reduceRegion(\n",
        "                    reducer=ee.Reducer.sum(),\n",
        "                    geometry=study_area,\n",
        "                    scale=1000,\n",
        "                    maxPixels=1e9\n",
        "                ).get('hotspot_presence')\n",
        "\n",
        "                # Create an image with the hotspot count\n",
        "                hotspot_count_image = ee.Image.constant(hotspot_count).rename('hotspot_count') \\\n",
        "                    .set('system:time_start', start.millis()) \\\n",
        "                    .set('system:index', start.format('YYYY_MM')) \\\n",
        "                    .set('year', year) \\\n",
        "                    .set('month', month)\n",
        "\n",
        "                return hotspot_count_image\n",
        "            else:\n",
        "                # No hotspots in this month\n",
        "                return ee.Image.constant(0).rename('hotspot_count') \\\n",
        "                    .set('system:time_start', start.millis()) \\\n",
        "                    .set('system:index', start.format('YYYY_MM')) \\\n",
        "                    .set('year', year) \\\n",
        "                    .set('month', month)\n",
        "\n",
        "        # สร้างรายการปี-เดือน\n",
        "        start_year = int(start_date.split('-')[0])\n",
        "        end_year = int(end_date.split('-')[0])\n",
        "        year_months = []\n",
        "\n",
        "        for year in range(start_year, end_year + 1):\n",
        "            start_month = 1 if year > start_year else int(start_date.split('-')[1])\n",
        "            end_month = 12 if year < end_year else int(end_date.split('-')[1])\n",
        "\n",
        "            for month in range(start_month, end_month + 1):\n",
        "                year_months.append(year * 100 + month)\n",
        "\n",
        "        year_months_ee = ee.List(year_months)\n",
        "\n",
        "        # สร้าง ImageCollection\n",
        "        monthly_images = year_months_ee.map(create_monthly_hotspot_composite)\n",
        "        monthly_composites = ee.ImageCollection.fromImages(monthly_images)\n",
        "\n",
        "        print(f\"จำนวนเดือนที่มี hotspot: {monthly_composites.size().getInfo()}\")\n",
        "\n",
        "        return monthly_composites.select(['hotspot_count'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting monthly hotspots: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันสร้างข้อมูลรวมรายเดือน - FIXED VERSION\n",
        "def create_monthly_dataset(ndvi_collection, study_area):\n",
        "    try:\n",
        "        # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "        if ndvi_collection is None:\n",
        "            print(\"ข้อมูล NDVI เป็น None\")\n",
        "            return None\n",
        "\n",
        "        ndvi_size = ndvi_collection.size().getInfo()\n",
        "        print(f\"NDVI collection size: {ndvi_size}\")\n",
        "\n",
        "        if ndvi_size == 0:\n",
        "            print(\"ไม่มีข้อมูล NDVI\")\n",
        "            return None\n",
        "\n",
        "        # ใช้วันที่ของ NDVI เป็นหลัก\n",
        "        ndvi_times = ndvi_collection.aggregate_array('system:time_start')\n",
        "        print(f\"จำนวนเดือนที่มีข้อมูล NDVI: {ndvi_times.size().getInfo()}\")\n",
        "\n",
        "        # ฟังก์ชันสำหรับรวมข้อมูลแต่ละเดือน - FIXED to avoid client-side operations\n",
        "        def combine_monthly_data(time_start):\n",
        "            # กรองข้อมูล NDVI ตามเวลา\n",
        "            ndvi_image = ndvi_collection.filter(ee.Filter.eq('system:time_start', time_start)).first()\n",
        "\n",
        "            # หา hotspot ในเดือนเดียวกับ NDVI\n",
        "            start_date = ee.Date(time_start)\n",
        "            end_date = start_date.advance(1, 'month')\n",
        "\n",
        "            # ดึงข้อมูล FIRMS ในช่วงเวลาเดียวกับ NDVI\n",
        "            firms_in_period = ee.ImageCollection('FIRMS') \\\n",
        "                .filterDate(start_date, end_date) \\\n",
        "                .filterBounds(study_area)\n",
        "\n",
        "            # 4. Change T21 to count hotspot - Convert to hotspot count\n",
        "            def count_hotspots(image):\n",
        "                return image.select('T21').gt(0).rename('hotspot_presence')\n",
        "\n",
        "            hotspot_presence = firms_in_period.map(count_hotspots)\n",
        "\n",
        "            # Sum hotspots spatially and temporally - FIXED to avoid client-side .getInfo()\n",
        "            monthly_hotspot_sum = hotspot_presence.sum()\n",
        "\n",
        "            # Use ee.Algorithms.If to handle empty collections without client-side operations\n",
        "            has_hotspots = hotspot_presence.size().gt(0)\n",
        "\n",
        "            hotspot_count_reduced = ee.Algorithms.If(\n",
        "                has_hotspots,\n",
        "                monthly_hotspot_sum.reduceRegion(\n",
        "                    reducer=ee.Reducer.sum(),\n",
        "                    geometry=study_area,\n",
        "                    scale=1000,\n",
        "                    maxPixels=1e9\n",
        "                ).get('hotspot_presence'),\n",
        "                0\n",
        "            )\n",
        "\n",
        "            # Create hotspot count image\n",
        "            hotspot_count_image = ee.Image.constant(hotspot_count_reduced).rename('hotspot_count')\n",
        "\n",
        "            # รวมภาพ\n",
        "            combined_image = ndvi_image.addBands(hotspot_count_image)\n",
        "\n",
        "            # ลดขนาดข้อมูลเป็นค่าเฉลี่ยของพื้นที่ศึกษา\n",
        "            reduced = combined_image.reduceRegion(\n",
        "                reducer=ee.Reducer.mean(),\n",
        "                geometry=study_area,\n",
        "                scale=1000,  # 1km resolution\n",
        "                maxPixels=1e9\n",
        "            )\n",
        "\n",
        "            # สร้าง Feature พร้อมวันที่\n",
        "            date_str = start_date.format('YYYY-MM-dd')\n",
        "            year = start_date.get('year')\n",
        "            month = start_date.get('month')\n",
        "\n",
        "            # Create properties dictionary properly\n",
        "            properties = reduced.combine({\n",
        "                'date': date_str,\n",
        "                'year': year,\n",
        "                'month': month\n",
        "            })\n",
        "\n",
        "            return ee.Feature(None, properties)\n",
        "\n",
        "        # แปลงเป็น FeatureCollection โดยใช้เวลาของ NDVI\n",
        "        ndvi_times_size = ndvi_times.size().getInfo()\n",
        "        if ndvi_times_size > 0:\n",
        "            combined_fc = ee.FeatureCollection(ndvi_times.map(combine_monthly_data))\n",
        "            return combined_fc\n",
        "        else:\n",
        "            print(\"ไม่มีข้อมูล NDVI\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating monthly dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันแปลง FeatureCollection เป็น DataFrame\n",
        "def fc_to_df(fc):\n",
        "    try:\n",
        "        # ดึงข้อมูลจาก GEE\n",
        "        features = fc.getInfo()['features']\n",
        "    except Exception as e:\n",
        "        print(\"ไม่สามารถดึงข้อมูลจาก GEE ได้:\", str(e))\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # สร้าง dictionary สำหรับเก็บข้อมูล - Updated to use hotspot_count\n",
        "    data_dict = {'date': [], 'NDVI': [], 'hotspot_count': [], 'year': [], 'month': []}\n",
        "\n",
        "    for feature in features:\n",
        "        props = feature['properties']\n",
        "        if 'NDVI' in props and props['NDVI'] is not None:\n",
        "            data_dict['date'].append(props.get('date', ''))\n",
        "            data_dict['NDVI'].append(props.get('NDVI', 0))\n",
        "            data_dict['hotspot_count'].append(props.get('hotspot_count', 0))\n",
        "            data_dict['year'].append(props.get('year', 0))\n",
        "            data_dict['month'].append(props.get('month', 0))\n",
        "\n",
        "    # สร้าง DataFrame\n",
        "    df = pd.DataFrame(data_dict)\n",
        "\n",
        "    # แปลงคอลัมน์ date เป็น datetime\n",
        "    if not df.empty:\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        df.sort_values('date', inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ฟังก์ชันเพิ่ม seasonal features\n",
        "def add_seasonal_features(df):\n",
        "    \"\"\"เพิ่ม features สำหรับฤดูกาล\"\"\"\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "\n",
        "    # ฤดูแล้ง (มีค.ค. - พ.ค.) และฤดูฝน (มิ.ย. - ต.ค.)\n",
        "    df['dry_season'] = ((df['month'] >= 11) | (df['month'] <= 5)).astype(int)\n",
        "    df['wet_season'] = ((df['month'] >= 6) & (df['month'] <= 10)).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# ฟังก์ชันเตรียมข้อมูลสำหรับการฝึกแบบจำลองรายเดือน - Updated for hotspot_count\n",
        "def prepare_monthly_training_data(df, sequence_length=6, target_column='hotspot_count'):\n",
        "    # ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "    if df.empty:\n",
        "        raise ValueError(\"ไม่มีข้อมูลใน DataFrame\")\n",
        "\n",
        "    print(f\"จำนวนข้อมูลดิบ: {len(df)}\")\n",
        "    print(f\"คอลัมน์ที่มี: {df.columns.tolist()}\")\n",
        "    print(f\"ตัวอย่างข้อมูล:\\n{df.head()}\")\n",
        "\n",
        "    # เพิ่ม seasonal features\n",
        "    df = add_seasonal_features(df)\n",
        "\n",
        "    # ล้างข้อมูลที่ขาดหาย\n",
        "    df_cleaned = df.fillna(0)\n",
        "    print(f\"จำนวนข้อมูลหลังล้าง: {len(df_cleaned)}\")\n",
        "    print(f\"ค่าสถิติพื้นฐาน:\\n{df_cleaned.describe()}\")\n",
        "\n",
        "    # ตรวจสอบว่ามีข้อมูลเพียงพอหลังจากล้างข้อมูล\n",
        "    min_required = sequence_length + 5\n",
        "    if len(df_cleaned) < min_required:\n",
        "        raise ValueError(f\"ข้อมูลไม่เพียงพอสำหรับการสร้างลำดับ ต้องการอย่างน้อย {min_required} ข้อมูล แต่มีเพียง {len(df_cleaned)}\")\n",
        "\n",
        "    # เตรียมข้อมูล feature และ target\n",
        "    feature_columns = ['NDVI', 'month_sin', 'month_cos', 'dry_season', 'wet_season']\n",
        "\n",
        "    # ตรวจสอบว่า target column มีอยู่\n",
        "    if target_column not in df_cleaned.columns:\n",
        "        target_column = 'hotspot_count'  # Default to hotspot_count\n",
        "        print(f\"ใช้ {target_column} เป็น target variable\")\n",
        "\n",
        "    X = df_cleaned[feature_columns].values\n",
        "    y = df_cleaned[[target_column]].values\n",
        "\n",
        "    print(f\"Features ที่ใช้: {feature_columns}\")\n",
        "    print(f\"Target ที่ใช้: {target_column}\")\n",
        "\n",
        "    # ปรับขนาดข้อมูล\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler_x = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "\n",
        "    X_scaled = scaler_x.fit_transform(X)\n",
        "    y_scaled = scaler_y.fit_transform(y)\n",
        "\n",
        "    # สร้างลำดับข้อมูลสำหรับ LSTM\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X_scaled) - sequence_length):\n",
        "        X_seq.append(X_scaled[i:i+sequence_length])\n",
        "        y_seq.append(y_scaled[i+sequence_length])\n",
        "\n",
        "    X_seq = np.array(X_seq)\n",
        "    y_seq = np.array(y_seq)\n",
        "\n",
        "    print(f\"จำนวนลำดับที่สร้างได้: {len(X_seq)}\")\n",
        "    print(f\"รูปร่างข้อมูล X: {X_seq.shape}, y: {y_seq.shape}\")\n",
        "\n",
        "    return X_seq, y_seq, scaler_x, scaler_y, df_cleaned\n",
        "\n",
        "# ฟังก์ชันสร้างแบบจำลอง LSTM สำหรับรายเดือน\n",
        "def create_monthly_lstm_model(sequence_length, n_features):\n",
        "    \"\"\"สร้างแบบจำลอง LSTM สำหรับทำนาย hotspot รายเดือน\"\"\"\n",
        "    try:\n",
        "        from tensorflow.keras.models import Sequential\n",
        "        from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "        from tensorflow.keras.optimizers import Adam\n",
        "        from tensorflow.keras.regularizers import l2\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        # LSTM layers with regularization\n",
        "        model.add(LSTM(64, return_sequences=True, input_shape=(sequence_length, n_features),\n",
        "                      kernel_regularizer=l2(0.001)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(LSTM(32, return_sequences=True,\n",
        "                      kernel_regularizer=l2(0.001)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(LSTM(16, return_sequences=False,\n",
        "                      kernel_regularizer=l2(0.001)))\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        # Dense layers\n",
        "        model.add(Dense(16, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        # Output layer\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                      loss='mse',\n",
        "                      metrics=['mae'])\n",
        "\n",
        "        return model\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import TensorFlow ได้ กรุณาติดตั้ง TensorFlow ก่อน\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างแบบจำลอง: {e}\")\n",
        "        return None\n",
        "\n",
        "# 5. Add learning curve chart\n",
        "def plot_learning_curve(history):\n",
        "    \"\"\"สร้างกราฟ Learning Curve\"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Loss curve\n",
        "        ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "        if 'val_loss' in history.history:\n",
        "            ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "        ax1.set_title(f'Model Loss Learning Curve ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss (MSE)')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # MAE curve\n",
        "        ax2.plot(history.history['mae'], label='Training MAE', color='blue')\n",
        "        if 'val_mae' in history.history:\n",
        "            ax2.plot(history.history['val_mae'], label='Validation MAE', color='red')\n",
        "        ax2.set_title(f'Model MAE Learning Curve ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Mean Absolute Error')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{siteName}_learning_curve.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(\"บันทึกกราฟ Learning Curve: learning_curve.png\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import matplotlib ได้\")\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างกราฟ Learning Curve: {e}\")\n",
        "\n",
        "# 6. Add actual vs predict chart\n",
        "def plot_actual_vs_predicted(y_true, y_pred, target_column='hotspot_count'):\n",
        "    \"\"\"สร้างกราฟ Actual vs Predicted\"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # Scatter plot\n",
        "        ax1.scatter(y_true, y_pred, alpha=0.6, color='blue')\n",
        "\n",
        "        # Perfect prediction line\n",
        "        min_val = min(min(y_true), min(y_pred))\n",
        "        max_val = max(max(y_true), max(y_pred))\n",
        "        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
        "\n",
        "        # Calculate metrics\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "        ax1.set_xlabel(f'Actual {target_column}')\n",
        "        ax1.set_ylabel(f'Predicted {target_column}')\n",
        "        ax1.set_title(f'Actual vs Predicted {target_column} ({siteName})\\nR² = {r2:.3f}, MAE = {mae:.3f}, RMSE = {rmse:.3f}')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Residual plot\n",
        "        residuals = y_true - y_pred\n",
        "        ax2.scatter(y_pred, residuals, alpha=0.6, color='green')\n",
        "        ax2.axhline(y=0, color='r', linestyle='--')\n",
        "        ax2.set_xlabel(f'Predicted {target_column}')\n",
        "        ax2.set_ylabel('Residuals')\n",
        "        ax2.set_title('Residual Plot')\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{siteName}_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(\"บันทึกกราฟ Actual vs Predicted: actual_vs_predicted.png\")\n",
        "\n",
        "        return r2, mae, rmse\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import matplotlib หรือ seaborn ได้\")\n",
        "        return None, None, None\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างกราฟ Actual vs Predicted: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# ฟังก์ชันทำนาย 12 เดือนข้างหน้า - Updated for hotspot_count\n",
        "def predict_next_12_months(model, last_sequence, scaler_x, scaler_y, df_cleaned, sequence_length=6):\n",
        "    \"\"\"ทำนายค่า hotspot สำหรับ 12 เดือนถัดไป\"\"\"\n",
        "\n",
        "    predictions = []\n",
        "    prediction_dates = []\n",
        "    current_sequence = last_sequence.copy()\n",
        "\n",
        "    # หาวันที่สุดท้ายในข้อมูล\n",
        "    last_date = df_cleaned['date'].iloc[-1]\n",
        "\n",
        "    for month_ahead in range(1, 13):  # ทำนาย 12 เดือนข้างหน้า\n",
        "        # ทำนายเดือนถัดไป\n",
        "        pred_scaled = model.predict(current_sequence, verbose=0)\n",
        "        pred_original = scaler_y.inverse_transform(pred_scaled)\n",
        "        predictions.append(pred_original[0][0])\n",
        "\n",
        "        # คำนวณวันที่ของเดือนถัดไป\n",
        "        if last_date.month == 12:\n",
        "            next_year = last_date.year + (last_date.month + month_ahead - 1) // 12\n",
        "            next_month = ((last_date.month + month_ahead - 1) % 12) + 1\n",
        "        else:\n",
        "            next_year = last_date.year + (last_date.month + month_ahead - 1) // 12\n",
        "            next_month = ((last_date.month + month_ahead - 1) % 12) + 1\n",
        "\n",
        "        # สร้างวันที่ที่ถูกต้อง\n",
        "        if next_month > 12:\n",
        "            next_year += 1\n",
        "            next_month = next_month - 12\n",
        "\n",
        "        prediction_date = datetime(next_year, next_month, 1)\n",
        "        prediction_dates.append(prediction_date)\n",
        "\n",
        "        # สร้าง features สำหรับเดือนถัดไป\n",
        "        month_sin = np.sin(2 * np.pi * next_month / 12)\n",
        "        month_cos = np.cos(2 * np.pi * next_month / 12)\n",
        "        dry_season = 1 if (next_month >= 11 or next_month <= 5) else 0\n",
        "        wet_season = 1 if (6 <= next_month <= 10) else 0\n",
        "\n",
        "        # สมมติค่า NDVI (ใช้ค่าเฉลี่ยจากข้อมูลเดือนเดียวกันในอดีต)\n",
        "        same_month_data = df_cleaned[df_cleaned['month'] == next_month]\n",
        "        if not same_month_data.empty:\n",
        "            avg_ndvi = same_month_data['NDVI'].mean()\n",
        "        else:\n",
        "            avg_ndvi = df_cleaned['NDVI'].mean()\n",
        "\n",
        "        # สร้าง feature vector สำหรับเดือนถัดไป\n",
        "        next_features = np.array([[avg_ndvi, month_sin, month_cos, dry_season, wet_season]])\n",
        "\n",
        "        # ปรับขนาดข้อมูล\n",
        "        next_features_scaled = scaler_x.transform(next_features)\n",
        "\n",
        "        # อัพเดท sequence สำหรับการทำนายครั้งถัดไป\n",
        "        current_sequence = np.roll(current_sequence, -1, axis=1)\n",
        "        current_sequence[0, -1] = next_features_scaled[0]\n",
        "\n",
        "    return predictions, prediction_dates\n",
        "\n",
        "# ฟังก์ชันสร้างกราฟทำนาย 12 เดือน - Updated for hotspot_count with full historical data\n",
        "def plot_12_month_prediction(df, predictions, prediction_dates, target_column='hotspot_count'):\n",
        "    \"\"\"แสดงกราฟข้อมูลจริงและการทำนาย 12 เดือน\"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "\n",
        "        # ใช้ style ที่สวยงาม\n",
        "        plt.style.use('default')\n",
        "        sns.set_palette(\"husl\")\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 9))\n",
        "\n",
        "        # กราฟที่ 1: ข้อมูลทั้งหมดตั้งแต่ 2018 + การทำนาย\n",
        "        # แสดงข้อมูลทั้งหมดตั้งแต่ 2018-01-01\n",
        "        ax1.plot(df['date'], df[target_column],\n",
        "                label=f'Historical {target_column} (2018-present)',\n",
        "                color='blue', marker='o', markersize=3, linewidth=1.5, alpha=0.8)\n",
        "\n",
        "        # แสดงข้อมูล 6 เดือนล่าสุดที่ใช้ทำนาย (highlight)\n",
        "        last_6_months = df.tail(6)\n",
        "        ax1.plot(last_6_months['date'], last_6_months[target_column],\n",
        "                label=f'Last 6 months (prediction input)',\n",
        "                color='orange', marker='s', markersize=6, linewidth=3, alpha=1.0)\n",
        "\n",
        "        # แสดงการทำนาย 12 เดือน\n",
        "        ax1.plot(prediction_dates, predictions,\n",
        "                label=f'12-month predictions', color='red', marker='*', markersize=8, linewidth=3)\n",
        "\n",
        "        # เชื่อมเส้นจากข้อมูลล่าสุดไปยังการทำนาย\n",
        "        ax1.plot([df['date'].iloc[-1], prediction_dates[0]],\n",
        "                [df[target_column].iloc[-1], predictions[0]],\n",
        "                '--', color='red', alpha=0.7, linewidth=2)\n",
        "\n",
        "        # เพิ่มข้อมูลสถิติบนกราฟ\n",
        "        historical_mean = df[target_column].mean()\n",
        "        historical_max = df[target_column].max()\n",
        "        historical_min = df[target_column].min()\n",
        "\n",
        "        ax1.axhline(y=historical_mean, color='gray', linestyle='--', alpha=0.7,\n",
        "                   label=f'Historical Mean ({historical_mean:.1f})')\n",
        "\n",
        "        ax1.set_title(f'{target_column} - Complete Historical Data (2018-present) & 12-Month Predictions ({siteName})',\n",
        "                     fontsize=16, fontweight='bold')\n",
        "        ax1.set_xlabel('Date', fontsize=12)\n",
        "        ax1.set_ylabel(f'{target_column} Value', fontsize=12)\n",
        "        ax1.legend(fontsize=10, loc='upper left')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # ปรับการแสดงวันที่ให้เหมาะกับข้อมูลหลายปี\n",
        "        ax1.tick_params(axis='x', rotation=45, labelsize=10)\n",
        "\n",
        "        # เพิ่ม text box แสดงสถิติ\n",
        "        stats_text = f'Historical Stats (2018-present):\\nMean: {historical_mean:.1f}\\nMax: {historical_max:.1f}\\nMin: {historical_min:.1f}\\nData Points: {len(df)}'\n",
        "        # ax1.text(0.02, 0.98, stats_text, transform=ax1.transAxes, fontsize=10,\n",
        "        #         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "        # กราฟที่ 2: Seasonal Pattern with Enhanced Information\n",
        "        months = [date.month for date in prediction_dates]\n",
        "        month_names = [calendar.month_name[month][:3] for month in months]\n",
        "\n",
        "        # Update color thresholds for hotspot count based on historical data\n",
        "        high_threshold = df[target_column].quantile(0.75)\n",
        "        medium_threshold = df[target_column].quantile(0.5)\n",
        "\n",
        "        colors = ['red' if pred > high_threshold else\n",
        "                 'orange' if pred > medium_threshold else 'green'\n",
        "                 for pred in predictions]\n",
        "\n",
        "        bars = ax2.bar(month_names, predictions, color=colors, alpha=0.7, edgecolor='black', linewidth=1)\n",
        "\n",
        "        # Add historical monthly averages for comparison\n",
        "        historical_monthly = df.groupby('month')[target_column].mean()\n",
        "        month_labels = [calendar.month_name[i][:3] for i in range(1, 13)]\n",
        "        historical_values = [historical_monthly.get(i, 0) for i in range(1, 13)]\n",
        "\n",
        "        # Show only the months we're predicting for comparison\n",
        "        pred_months = [date.month for date in prediction_dates]\n",
        "        historical_comparison = [historical_monthly.get(month, 0) for month in pred_months]\n",
        "\n",
        "        ax2_twin = ax2.twinx()\n",
        "        ax2_twin.plot(month_names, historical_comparison, 'k--', marker='d',\n",
        "                     linewidth=2, markersize=6, label='Historical Monthly Average', alpha=0.8)\n",
        "        ax2_twin.set_ylabel('Historical Average', fontsize=12, color='black')\n",
        "        ax2_twin.tick_params(axis='y', labelcolor='black')\n",
        "\n",
        "        ax2.set_title(f'Monthly Hotspot Count Predictions vs Historical Averages (Next 12 Months) ({siteName})',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "        ax2.set_xlabel('Month', fontsize=12)\n",
        "        ax2.set_ylabel(f'Predicted {target_column}', fontsize=12)\n",
        "        ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "        # เพิ่มค่าบนแท่งกราฟ\n",
        "        for bar, pred in zip(bars, predictions):\n",
        "            height = bar.get_height()\n",
        "            ax2.annotate(f'{pred:.0f}',\n",
        "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                        xytext=(0, 3),  # 3 points vertical offset\n",
        "                        textcoords=\"offset points\",\n",
        "                        ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # เพิ่ม legend สำหรับสี\n",
        "        import matplotlib.patches as mpatches\n",
        "        high_patch = mpatches.Patch(color='red', alpha=0.7, label=f'High Risk (>{high_threshold:.0f})')\n",
        "        medium_patch = mpatches.Patch(color='orange', alpha=0.7, label=f'Medium Risk ({medium_threshold:.0f}-{high_threshold:.0f})')\n",
        "        low_patch = mpatches.Patch(color='green', alpha=0.7, label=f'Low Risk (<{medium_threshold:.0f})')\n",
        "\n",
        "        # Combine legends from both axes\n",
        "        bars_legend = [high_patch, medium_patch, low_patch]\n",
        "        line_legend = ax2_twin.get_legend_handles_labels()\n",
        "\n",
        "        ax2.legend(handles=bars_legend, loc='upper left')\n",
        "        ax2_twin.legend(loc='upper right')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{siteName}_12_month_prediction.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"บันทึกกราฟทำนาย 12 เดือน: {siteName}_12_month_prediction.png\")\n",
        "\n",
        "        # Print summary of changes from historical averages\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"การเปรียบเทียบการทำนายกับค่าเฉลี่ยในอดีต:\")\n",
        "        print(\"=\"*60)\n",
        "        for i, (month_name, pred, hist) in enumerate(zip(month_names, predictions, historical_comparison)):\n",
        "            diff = pred - hist\n",
        "            change_pct = (diff / hist * 100) if hist > 0 else 0\n",
        "            status = \"↑ เพิ่มขึ้น\" if diff > 0 else \"↓ ลดลง\" if diff < 0 else \"→ ไม่เปลี่ยนแปลง\"\n",
        "            print(f\"{month_name}: ทำนาย {pred:.0f}, เฉลี่ยในอดีต {hist:.1f}, ต่าง {diff:+.1f} ({change_pct:+.1f}%) {status}\")\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import matplotlib หรือ seaborn ได้\")\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างกราฟทำนาย 12 เดือน: {e}\")\n",
        "\n",
        "# ฟังก์ชันสร้างตารางสรุปการทำนาย 12 เดือน - Updated for hotspot_count\n",
        "def create_prediction_summary_table(predictions, prediction_dates, target_column='hotspot_count'):\n",
        "    \"\"\"สร้างตารางสรุปการทำนาย\"\"\"\n",
        "    try:\n",
        "        # สร้าง DataFrame สำหรับการทำนาย\n",
        "        pred_df = pd.DataFrame({\n",
        "            'Date': prediction_dates,\n",
        "            'Month': [calendar.month_name[date.month] for date in prediction_dates],\n",
        "            'Year': [date.year for date in prediction_dates],\n",
        "            f'Predicted_{target_column}': predictions\n",
        "        })\n",
        "\n",
        "        # เพิ่มคอลัมน์ Risk Level - Updated thresholds for hotspot count\n",
        "        def get_risk_level(value):\n",
        "            if value > 50:  # Adjusted for hotspot count\n",
        "                return 'High Risk'\n",
        "            elif value > 25:  # Adjusted for hotspot count\n",
        "                return 'Medium Risk'\n",
        "            else:\n",
        "                return 'Low Risk'\n",
        "\n",
        "        pred_df['Risk_Level'] = pred_df[f'Predicted_{target_column}'].apply(get_risk_level)\n",
        "\n",
        "        # เพิ่มคอลัมน์ฤดู\n",
        "        def get_season(month):\n",
        "            if month in ['December', 'January', 'February', 'March', 'April', 'May']:\n",
        "                return 'Dry Season'\n",
        "            else:\n",
        "                return 'Wet Season'\n",
        "\n",
        "        pred_df['Season'] = pred_df['Month'].apply(get_season)\n",
        "\n",
        "        # จัดรูปแบบตาราง\n",
        "        pred_df[f'Predicted_{target_column}'] = pred_df[f'Predicted_{target_column}'].round(0)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"สรุปการทำนาย HOTSPOT COUNT รายเดือนสำหรับ 12 เดือนข้างหน้า\")\n",
        "        print(\"=\"*80)\n",
        "        print(pred_df.to_string(index=False))\n",
        "\n",
        "        # สถิติสรุป\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"สถิติสรุป\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"ค่าเฉลี่ย: {pred_df[f'Predicted_{target_column}'].mean():.0f} hotspots\")\n",
        "        print(f\"ค่าสูงสุด: {pred_df[f'Predicted_{target_column}'].max():.0f} hotspots ({pred_df.loc[pred_df[f'Predicted_{target_column}'].idxmax(), 'Month']})\")\n",
        "        print(f\"ค่าต่ำสุด: {pred_df[f'Predicted_{target_column}'].min():.0f} hotspots ({pred_df.loc[pred_df[f'Predicted_{target_column}'].idxmin(), 'Month']})\")\n",
        "\n",
        "        # สรุปตามระดับความเสี่ยง\n",
        "        risk_summary = pred_df['Risk_Level'].value_counts()\n",
        "        print(f\"\\nสรุปตามระดับความเสี่ยง:\")\n",
        "        for risk, count in risk_summary.items():\n",
        "            print(f\"  {risk}: {count} เดือน ({count/12*100:.1f}%)\")\n",
        "\n",
        "        # สรุปตามฤดู\n",
        "        season_summary = pred_df.groupby('Season')[f'Predicted_{target_column}'].agg(['mean', 'max', 'min'])\n",
        "        print(f\"\\nสรุปตามฤดู:\")\n",
        "        for season in season_summary.index:\n",
        "            print(f\"  {season}:\")\n",
        "            print(f\"    ค่าเฉลี่ย: {season_summary.loc[season, 'mean']:.0f} hotspots\")\n",
        "            print(f\"    ค่าสูงสุด: {season_summary.loc[season, 'max']:.0f} hotspots\")\n",
        "            print(f\"    ค่าต่ำสุด: {season_summary.loc[season, 'min']:.0f} hotspots\")\n",
        "\n",
        "        # บันทึกตารางเป็นไฟล์ CSV\n",
        "        pred_df.to_csv(f'{siteName}_12_month_hotspot_predictions.csv', index=False)\n",
        "        print(f\"\\nบันทึกตารางการทำนาย: {siteName}_12_month_hotspot_predictions.csv\")\n",
        "\n",
        "        return pred_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างตารางสรุป: {e}\")\n",
        "        return None\n",
        "\n",
        "# ฟังก์ชันประเมินผลแบบจำลอง\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f'MSE: {mse:.4f}')\n",
        "    print(f'RMSE: {rmse:.4f}')\n",
        "    print(f'MAE: {mae:.4f}')\n",
        "    print(f'R²: {r2:.4f}')\n",
        "\n",
        "    return mse, rmse, mae, r2\n",
        "\n",
        "\n",
        "# Enhanced visualization functions for NDVI vs Hotspot time series analysis\n",
        "\n",
        "def plot_ndvi_hotspot_time_series(df, save_plot=True):\n",
        "    \"\"\"\n",
        "    Create comprehensive time series plots showing NDVI vs Hotspot count relationship\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "        from datetime import datetime\n",
        "        import numpy as np\n",
        "\n",
        "        # Set style for better looking plots\n",
        "        plt.style.use('default')\n",
        "        sns.set_palette(\"husl\")\n",
        "\n",
        "        # Create figure with multiple subplots\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "        # 1. Main time series plot with dual y-axes\n",
        "        ax1 = plt.subplot(3, 2, (1, 2))  # Top row, spans 2 columns\n",
        "\n",
        "        # Plot NDVI on primary y-axis\n",
        "        line1 = ax1.plot(df['date'], df['NDVI'],\n",
        "                        color='green', linewidth=2, marker='o', markersize=4,\n",
        "                        label='NDVI', alpha=0.8)\n",
        "        ax1.set_xlabel('Date', fontsize=12)\n",
        "        ax1.set_ylabel('NDVI', fontsize=12, color='green')\n",
        "        ax1.tick_params(axis='y', labelcolor='green')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Create secondary y-axis for hotspot count\n",
        "        ax2 = ax1.twinx()\n",
        "        line2 = ax2.plot(df['date'], df['hotspot_count'],\n",
        "                        color='red', linewidth=2, marker='s', markersize=4,\n",
        "                        label='Hotspot Count', alpha=0.8)\n",
        "        ax2.set_ylabel('Hotspot Count', fontsize=12, color='red')\n",
        "        ax2.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "        # Add correlation coefficient to title\n",
        "        correlation = df['NDVI'].corr(df['hotspot_count'])\n",
        "        ax1.set_title(f'NDVI vs Hotspot Count Time Series ({siteName})\\nCorrelation: {correlation:.3f}',\n",
        "                     fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "        # Combine legends\n",
        "        lines = line1 + line2\n",
        "        labels = [l.get_label() for l in lines]\n",
        "        ax1.legend(lines, labels, loc='upper left', fontsize=10)\n",
        "\n",
        "        # Rotate x-axis labels for better readability\n",
        "        ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # 2. Scatter plot showing correlation\n",
        "        ax3 = plt.subplot(3, 2, 3)\n",
        "        scatter = ax3.scatter(df['NDVI'], df['hotspot_count'],\n",
        "                             c=df.index, cmap='viridis', alpha=0.6, s=50)\n",
        "        ax3.set_xlabel('NDVI', fontsize=12)\n",
        "        ax3.set_ylabel('Hotspot Count', fontsize=12)\n",
        "        ax3.set_title(f'NDVI vs Hotspot Count Scatter Plot ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add trend line\n",
        "        z = np.polyfit(df['NDVI'], df['hotspot_count'], 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax3.plot(df['NDVI'], p(df['NDVI']), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "        # Add colorbar for time progression\n",
        "        cbar = plt.colorbar(scatter, ax=ax3)\n",
        "        cbar.set_label('Time Progression', fontsize=10)\n",
        "\n",
        "        # 3. Monthly averages comparison\n",
        "        ax4 = plt.subplot(3, 2, 4)\n",
        "        monthly_avg = df.groupby('month').agg({\n",
        "            'NDVI': 'mean',\n",
        "            'hotspot_count': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Create month names\n",
        "        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
        "                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "        monthly_avg['month_name'] = [month_names[i-1] for i in monthly_avg['month']]\n",
        "\n",
        "        ax4_twin = ax4.twinx()\n",
        "\n",
        "        bars1 = ax4.bar([x - 0.2 for x in range(len(monthly_avg))], monthly_avg['NDVI'],\n",
        "                       width=0.4, color='green', alpha=0.7, label='NDVI')\n",
        "        bars2 = ax4_twin.bar([x + 0.2 for x in range(len(monthly_avg))], monthly_avg['hotspot_count'],\n",
        "                            width=0.4, color='red', alpha=0.7, label='Hotspot Count')\n",
        "\n",
        "        ax4.set_xlabel('Month', fontsize=12)\n",
        "        ax4.set_ylabel('Average NDVI', fontsize=12, color='green')\n",
        "        ax4_twin.set_ylabel('Average Hotspot Count', fontsize=12, color='red')\n",
        "        ax4.set_title(f'Monthly Averages Comparison ({siteName})', fontsize=14, fontweight='bold')\n",
        "\n",
        "        ax4.set_xticks(range(len(monthly_avg)))\n",
        "        ax4.set_xticklabels(monthly_avg['month_name'], rotation=45)\n",
        "        ax4.tick_params(axis='y', labelcolor='green')\n",
        "        ax4_twin.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "        # Add legends\n",
        "        ax4.legend(loc='upper left')\n",
        "        ax4_twin.legend(loc='upper right')\n",
        "\n",
        "        # 4. Seasonal analysis\n",
        "        ax5 = plt.subplot(3, 2, 5)\n",
        "\n",
        "        # Define seasons\n",
        "        def get_season_name(month):\n",
        "            if month in [12, 1, 2]:\n",
        "                return 'Winter'\n",
        "            elif month in [3, 4, 5]:\n",
        "                return 'Spring'\n",
        "            elif month in [6, 7, 8]:\n",
        "                return 'Summer'\n",
        "            else:\n",
        "                return 'Autumn'\n",
        "\n",
        "        df['season'] = df['month'].apply(get_season_name)\n",
        "        seasonal_stats = df.groupby('season').agg({\n",
        "            'NDVI': ['mean', 'std'],\n",
        "            'hotspot_count': ['mean', 'std']\n",
        "        }).round(3)\n",
        "\n",
        "        seasons = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
        "        ndvi_means = [seasonal_stats.loc[s, ('NDVI', 'mean')] for s in seasons]\n",
        "        ndvi_stds = [seasonal_stats.loc[s, ('NDVI', 'std')] for s in seasons]\n",
        "        hotspot_means = [seasonal_stats.loc[s, ('hotspot_count', 'mean')] for s in seasons]\n",
        "        hotspot_stds = [seasonal_stats.loc[s, ('hotspot_count', 'std')] for s in seasons]\n",
        "\n",
        "        x_pos = np.arange(len(seasons))\n",
        "\n",
        "        ax5_twin = ax5.twinx()\n",
        "\n",
        "        bars1 = ax5.bar(x_pos - 0.2, ndvi_means, 0.4, yerr=ndvi_stds,\n",
        "                       color='green', alpha=0.7, capsize=5, label='NDVI')\n",
        "        bars2 = ax5_twin.bar(x_pos + 0.2, hotspot_means, 0.4, yerr=hotspot_stds,\n",
        "                            color='red', alpha=0.7, capsize=5, label='Hotspot Count')\n",
        "\n",
        "        ax5.set_xlabel('Season', fontsize=12)\n",
        "        ax5.set_ylabel('Average NDVI', fontsize=12, color='green')\n",
        "        ax5_twin.set_ylabel('Average Hotspot Count', fontsize=12, color='red')\n",
        "        ax5.set_title(f'Seasonal Analysis with Standard Deviation ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax5.set_xticks(x_pos)\n",
        "        ax5.set_xticklabels(seasons)\n",
        "        ax5.tick_params(axis='y', labelcolor='green')\n",
        "        ax5_twin.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "        ax5.legend(loc='upper left')\n",
        "        ax5_twin.legend(loc='upper right')\n",
        "\n",
        "        # 5. Moving averages\n",
        "        ax6 = plt.subplot(3, 2, 6)\n",
        "\n",
        "        # Calculate moving averages\n",
        "        window = 6  # 6-month moving average\n",
        "        df['NDVI_ma'] = df['NDVI'].rolling(window=window, center=True).mean()\n",
        "        df['hotspot_ma'] = df['hotspot_count'].rolling(window=window, center=True).mean()\n",
        "\n",
        "        line1 = ax6.plot(df['date'], df['NDVI_ma'],\n",
        "                        color='darkgreen', linewidth=3, label=f'NDVI {window}-month MA')\n",
        "\n",
        "        ax6_twin = ax6.twinx()\n",
        "        line2 = ax6_twin.plot(df['date'], df['hotspot_ma'],\n",
        "                             color='darkred', linewidth=3, label=f'Hotspot {window}-month MA')\n",
        "\n",
        "        ax6.set_xlabel('Date', fontsize=12)\n",
        "        ax6.set_ylabel('NDVI Moving Average', fontsize=12, color='darkgreen')\n",
        "        ax6_twin.set_ylabel('Hotspot Moving Average', fontsize=12, color='darkred')\n",
        "        ax6.set_title(f'{window}-Month Moving Averages ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax6.tick_params(axis='x', rotation=45)\n",
        "        ax6.tick_params(axis='y', labelcolor='darkgreen')\n",
        "        ax6_twin.tick_params(axis='y', labelcolor='darkred')\n",
        "        ax6.grid(True, alpha=0.3)\n",
        "\n",
        "        ax6.legend(loc='upper left')\n",
        "        ax6_twin.legend(loc='upper right')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_plot:\n",
        "            plt.savefig(f'{siteName}_ndvi_hotspot_time_series_analysis.png', dpi=300, bbox_inches='tight')\n",
        "            print(f\"บันทึกกราฟ NDVI vs Hotspot Time Series: {siteName}_ndvi_hotspot_time_series_analysis.png\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # Print correlation analysis\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"การวิเคราะห์ความสัมพันธ์ NDVI vs Hotspot Count\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Pearson Correlation: {correlation:.4f}\")\n",
        "\n",
        "        # Lag correlation analysis\n",
        "        print(\"\\nLag Correlation Analysis:\")\n",
        "        for lag in range(1, 7):\n",
        "            lag_corr = df['NDVI'].corr(df['hotspot_count'].shift(lag))\n",
        "            print(f\"NDVI vs Hotspot (lag {lag} months): {lag_corr:.4f}\")\n",
        "\n",
        "        # Seasonal correlation\n",
        "        print(f\"\\nSeasonal Correlations:\")\n",
        "        for season in seasons:\n",
        "            season_data = df[df['season'] == season]\n",
        "            if len(season_data) > 1:\n",
        "                season_corr = season_data['NDVI'].corr(season_data['hotspot_count'])\n",
        "                print(f\"{season}: {season_corr:.4f}\")\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import matplotlib หรือ seaborn ได้\")\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างกราฟ time series: {e}\")\n",
        "\n",
        "\n",
        "def plot_yearly_comparison(df, save_plot=True):\n",
        "    \"\"\"\n",
        "    Create yearly comparison plots for NDVI and Hotspot trends\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        import seaborn as sns\n",
        "\n",
        "        # Extract year from date\n",
        "        df['year'] = df['date'].dt.year\n",
        "        years = sorted(df['year'].unique())\n",
        "\n",
        "        fig, ((ax3, ax2), (ax1, ax4)) = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "        # 1. Yearly averages line plot\n",
        "        yearly_avg = df.groupby('year').agg({\n",
        "            'NDVI': 'mean',\n",
        "            'hotspot_count': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        ax1_twin = ax1.twinx()\n",
        "\n",
        "        line1 = ax1.plot(yearly_avg['year'], yearly_avg['NDVI'],\n",
        "                        color='green', marker='o', linewidth=3, markersize=8, label='NDVI')\n",
        "        line2 = ax1_twin.plot(yearly_avg['year'], yearly_avg['hotspot_count'],\n",
        "                             color='red', marker='s', linewidth=3, markersize=8, label='Hotspot Count')\n",
        "\n",
        "        ax1.set_xlabel('Year', fontsize=12)\n",
        "        ax1.set_ylabel('Average NDVI', fontsize=12, color='green')\n",
        "        ax1_twin.set_ylabel('Average Hotspot Count', fontsize=12, color='red')\n",
        "        ax1.set_title(f'Yearly Averages Trend ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax1.tick_params(axis='y', labelcolor='green')\n",
        "        ax1_twin.tick_params(axis='y', labelcolor='red')\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        lines = line1 + line2\n",
        "        labels = [l.get_label() for l in lines]\n",
        "        ax1.legend(lines, labels, loc='upper left')\n",
        "\n",
        "        # 2. Heatmap of monthly values by year for NDVI\n",
        "        pivot_ndvi = df.pivot_table(values='NDVI', index='year', columns='month', aggfunc='mean')\n",
        "        sns.heatmap(pivot_ndvi, annot=True, fmt='.3f', cmap='RdYlGn', ax=ax2, cbar_kws={'label': 'NDVI'})\n",
        "        ax2.set_title(f'NDVI Monthly Heatmap by Year ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax2.set_xlabel('Month', fontsize=12)\n",
        "        ax2.set_ylabel('Year', fontsize=12)\n",
        "\n",
        "        # 3. Heatmap of monthly values by year for Hotspot Count\n",
        "        pivot_hotspot = df.pivot_table(values='hotspot_count', index='year', columns='month', aggfunc='mean')\n",
        "        sns.heatmap(pivot_hotspot, annot=True, fmt='.1f', cmap='Reds', ax=ax3, cbar_kws={'label': 'Hotspot Count'})\n",
        "        ax3.set_title(f'Hotspot Count Monthly Heatmap by Year ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax3.set_xlabel('Month', fontsize=12)\n",
        "        ax3.set_ylabel('Year', fontsize=12)\n",
        "\n",
        "        # 4. Box plots for distribution comparison\n",
        "        years_to_plot = years[-5:] if len(years) > 5 else years  # Last 5 years or all if less\n",
        "\n",
        "        df_recent = df[df['year'].isin(years_to_plot)]\n",
        "\n",
        "        ax4_twin = ax4.twinx()\n",
        "\n",
        "        # NDVI box plot\n",
        "        ndvi_data = [df_recent[df_recent['year'] == year]['NDVI'].values for year in years_to_plot]\n",
        "        bp1 = ax4.boxplot(ndvi_data, positions=[x - 0.2 for x in range(len(years_to_plot))],\n",
        "                         widths=0.3, patch_artist=True, boxprops=dict(facecolor='lightgreen'))\n",
        "\n",
        "        # Hotspot box plot\n",
        "        hotspot_data = [df_recent[df_recent['year'] == year]['hotspot_count'].values for year in years_to_plot]\n",
        "        bp2 = ax4_twin.boxplot(hotspot_data, positions=[x + 0.2 for x in range(len(years_to_plot))],\n",
        "                              widths=0.3, patch_artist=True, boxprops=dict(facecolor='lightcoral'))\n",
        "\n",
        "        ax4.set_xlabel('Year', fontsize=12)\n",
        "        ax4.set_ylabel('NDVI Distribution', fontsize=12, color='green')\n",
        "        ax4_twin.set_ylabel('Hotspot Count Distribution', fontsize=12, color='red')\n",
        "        ax4.set_title(f'Distribution Comparison (Last {len(years_to_plot)} Years) ({siteName})', fontsize=14, fontweight='bold')\n",
        "        ax4.set_xticks(range(len(years_to_plot)))\n",
        "        ax4.set_xticklabels(years_to_plot)\n",
        "        ax4.tick_params(axis='y', labelcolor='green')\n",
        "        ax4_twin.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "        # Add legend for box plots\n",
        "        from matplotlib.patches import Patch\n",
        "        legend_elements = [Patch(facecolor='lightgreen', label='NDVI'),\n",
        "                          Patch(facecolor='lightcoral', label='Hotspot Count')]\n",
        "        ax4.legend(handles=legend_elements, loc='upper left')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if save_plot:\n",
        "            plt.savefig(f'{siteName}_yearly_comparison_analysis.png', dpi=300, bbox_inches='tight')\n",
        "            print(f\"บันทึกกราฟ Yearly Comparison: {siteName}_yearly_comparison_analysis.png\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"ไม่สามารถ import matplotlib หรือ seaborn ได้\")\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างกราฟ yearly comparison: {e}\")\n",
        "\n",
        "\n",
        "def create_comprehensive_analysis_report(df, save_report=True):\n",
        "    \"\"\"\n",
        "    Create a comprehensive statistical report of NDVI vs Hotspot relationship\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "        from scipy import stats\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"COMPREHENSIVE ANALYSIS REPORT: NDVI vs HOTSPOT COUNT\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Basic statistics\n",
        "        print(\"\\n1. BASIC STATISTICS\")\n",
        "        print(\"-\" * 40)\n",
        "        stats_df = df[['NDVI', 'hotspot_count']].describe()\n",
        "        print(stats_df)\n",
        "\n",
        "        # Correlation analysis\n",
        "        print(\"\\n2. CORRELATION ANALYSIS\")\n",
        "        print(\"-\" * 40)\n",
        "        correlation_matrix = df[['NDVI', 'hotspot_count', 'month', 'year']].corr()\n",
        "        print(\"Correlation Matrix:\")\n",
        "        print(correlation_matrix)\n",
        "\n",
        "        # Statistical significance test\n",
        "        corr_coef, p_value = stats.pearsonr(df['NDVI'], df['hotspot_count'])\n",
        "        print(f\"\\nPearson Correlation Coefficient: {corr_coef:.4f}\")\n",
        "        print(f\"P-value: {p_value:.4f}\")\n",
        "        print(f\"Statistical Significance: {'Yes' if p_value < 0.05 else 'No'} (α = 0.05)\")\n",
        "\n",
        "        # Seasonal analysis\n",
        "        print(\"\\n3. SEASONAL ANALYSIS\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Define seasons\n",
        "        def get_season(month):\n",
        "            if month in [12, 1, 2]:\n",
        "                return 'Winter'\n",
        "            elif month in [3, 4, 5]:\n",
        "                return 'Spring'\n",
        "            elif month in [6, 7, 8]:\n",
        "                return 'Summer'\n",
        "            else:\n",
        "                return 'Autumn'\n",
        "\n",
        "        df['season'] = df['month'].apply(get_season)\n",
        "\n",
        "        seasonal_analysis = df.groupby('season').agg({\n",
        "            'NDVI': ['mean', 'std', 'min', 'max'],\n",
        "            'hotspot_count': ['mean', 'std', 'min', 'max']\n",
        "        }).round(4)\n",
        "\n",
        "        print(\"Seasonal Statistics:\")\n",
        "        print(seasonal_analysis)\n",
        "\n",
        "        # Monthly trends\n",
        "        print(\"\\n4. MONTHLY TRENDS\")\n",
        "        print(\"-\" * 40)\n",
        "        monthly_analysis = df.groupby('month').agg({\n",
        "            'NDVI': ['mean', 'std'],\n",
        "            'hotspot_count': ['mean', 'std']\n",
        "        }).round(4)\n",
        "\n",
        "        print(\"Monthly Statistics:\")\n",
        "        print(monthly_analysis)\n",
        "\n",
        "        # Identify peak months\n",
        "        peak_ndvi_month = df.groupby('month')['NDVI'].mean().idxmax()\n",
        "        peak_hotspot_month = df.groupby('month')['hotspot_count'].mean().idxmax()\n",
        "        low_ndvi_month = df.groupby('month')['NDVI'].mean().idxmin()\n",
        "        low_hotspot_month = df.groupby('month')['hotspot_count'].mean().idxmin()\n",
        "\n",
        "        month_names = {1: 'January', 2: 'February', 3: 'March', 4: 'April',\n",
        "                      5: 'May', 6: 'June', 7: 'July', 8: 'August',\n",
        "                      9: 'September', 10: 'October', 11: 'November', 12: 'December'}\n",
        "\n",
        "        print(f\"\\nPeak NDVI Month: {month_names[peak_ndvi_month]} ({peak_ndvi_month})\")\n",
        "        print(f\"Lowest NDVI Month: {month_names[low_ndvi_month]} ({low_ndvi_month})\")\n",
        "        print(f\"Peak Hotspot Month: {month_names[peak_hotspot_month]} ({peak_hotspot_month})\")\n",
        "        print(f\"Lowest Hotspot Month: {month_names[low_hotspot_month]} ({low_hotspot_month})\")\n",
        "\n",
        "        # Trend analysis\n",
        "        print(\"\\n5. TREND ANALYSIS\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Linear regression for trends\n",
        "        from sklearn.linear_model import LinearRegression\n",
        "\n",
        "        # NDVI trend over time\n",
        "        X = df.index.values.reshape(-1, 1)\n",
        "        y_ndvi = df['NDVI'].values\n",
        "        y_hotspot = df['hotspot_count'].values\n",
        "\n",
        "        reg_ndvi = LinearRegression().fit(X, y_ndvi)\n",
        "        reg_hotspot = LinearRegression().fit(X, y_hotspot)\n",
        "\n",
        "        ndvi_slope = reg_ndvi.coef_[0]\n",
        "        hotspot_slope = reg_hotspot.coef_[0]\n",
        "\n",
        "        print(f\"NDVI Trend: {ndvi_slope:.6f} units per month\")\n",
        "        print(f\"Hotspot Trend: {hotspot_slope:.4f} count per month\")\n",
        "\n",
        "        trend_direction_ndvi = \"Increasing\" if ndvi_slope > 0 else \"Decreasing\" if ndvi_slope < 0 else \"Stable\"\n",
        "        trend_direction_hotspot = \"Increasing\" if hotspot_slope > 0 else \"Decreasing\" if hotspot_slope < 0 else \"Stable\"\n",
        "\n",
        "        print(f\"NDVI Overall Trend: {trend_direction_ndvi}\")\n",
        "        print(f\"Hotspot Overall Trend: {trend_direction_hotspot}\")\n",
        "\n",
        "        # Anomaly detection\n",
        "        print(\"\\n6. ANOMALY DETECTION\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Define anomalies as values beyond 2 standard deviations\n",
        "        ndvi_mean, ndvi_std = df['NDVI'].mean(), df['NDVI'].std()\n",
        "        hotspot_mean, hotspot_std = df['hotspot_count'].mean(), df['hotspot_count'].std()\n",
        "\n",
        "        ndvi_anomalies = df[(df['NDVI'] < ndvi_mean - 2*ndvi_std) | (df['NDVI'] > ndvi_mean + 2*ndvi_std)]\n",
        "        hotspot_anomalies = df[(df['hotspot_count'] < hotspot_mean - 2*hotspot_std) | (df['hotspot_count'] > hotspot_mean + 2*hotspot_std)]\n",
        "\n",
        "        print(f\"NDVI Anomalies: {len(ndvi_anomalies)} records\")\n",
        "        print(f\"Hotspot Anomalies: {len(hotspot_anomalies)} records\")\n",
        "\n",
        "        if len(ndvi_anomalies) > 0:\n",
        "            print(\"\\nNDVI Anomaly Dates:\")\n",
        "            for idx, row in ndvi_anomalies.iterrows():\n",
        "                print(f\"  {row['date'].strftime('%Y-%m-%d')}: NDVI = {row['NDVI']:.4f}\")\n",
        "\n",
        "        if len(hotspot_anomalies) > 0:\n",
        "            print(\"\\nHotspot Anomaly Dates:\")\n",
        "            for idx, row in hotspot_anomalies.iterrows():\n",
        "                print(f\"  {row['date'].strftime('%Y-%m-%d')}: Hotspot Count = {row['hotspot_count']:.0f}\")\n",
        "\n",
        "        # Save report to file\n",
        "        if save_report:\n",
        "            report_content = []\n",
        "            report_content.append(\"COMPREHENSIVE ANALYSIS REPORT: NDVI vs HOTSPOT COUNT\")\n",
        "            report_content.append(\"=\"*80)\n",
        "            report_content.append(f\"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            report_content.append(f\"Data Period: {df['date'].min().strftime('%Y-%m-%d')} to {df['date'].max().strftime('%Y-%m-%d')}\")\n",
        "            report_content.append(f\"Total Records: {len(df)}\")\n",
        "            report_content.append(\"\")\n",
        "            report_content.append(\"KEY FINDINGS:\")\n",
        "            report_content.append(f\"• Overall Correlation: {corr_coef:.4f} ({'Strong' if abs(corr_coef) > 0.7 else 'Moderate' if abs(corr_coef) > 0.3 else 'Weak'})\")\n",
        "            report_content.append(f\"• Statistical Significance: {'Yes' if p_value < 0.05 else 'No'}\")\n",
        "            report_content.append(f\"• NDVI Trend: {trend_direction_ndvi}\")\n",
        "            report_content.append(f\"• Hotspot Trend: {trend_direction_hotspot}\")\n",
        "            report_content.append(f\"• Peak NDVI Month: {month_names[peak_ndvi_month]}\")\n",
        "            report_content.append(f\"• Peak Hotspot Month: {month_names[peak_hotspot_month]}\")\n",
        "\n",
        "            with open(f'{siteName}_ndvi_hotspot_analysis_report.txt', 'w', encoding='utf-8') as f:\n",
        "                f.write('\\n'.join(report_content))\n",
        "\n",
        "            print(f\"\\nบันทึกรายงานการวิเคราะห์: {siteName}_ndvi_hotspot_analysis_report.txt\")\n",
        "\n",
        "        return {\n",
        "            'correlation': corr_coef,\n",
        "            'p_value': p_value,\n",
        "            'seasonal_stats': seasonal_analysis,\n",
        "            'monthly_stats': monthly_analysis,\n",
        "            'trends': {'ndvi_slope': ndvi_slope, 'hotspot_slope': hotspot_slope},\n",
        "            'anomalies': {'ndvi': ndvi_anomalies, 'hotspot': hotspot_anomalies}\n",
        "        }\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"ไม่สามารถ import required libraries: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"เกิดข้อผิดพลาดในการสร้างรายงาน: {e}\")\n",
        "\n",
        "# รันโค้ดหลักสำหรับการทำนายรายเดือน - Updated main function\n",
        "def main():\n",
        "    print(\"เริ่มการวิเคราะห์และทำนาย HOTSPOT COUNT รายเดือนสำหรับ 12 เดือนข้างหน้า\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # กำหนดช่วงเวลาข้อมูล (เพิ่มข้อมูลให้มากขึ้น)\n",
        "    start_date = '2017-08-01'\n",
        "    end_date = '2025-08-31'\n",
        "\n",
        "    print(\"กำลังดึงข้อมูล NDVI รายเดือนจาก Google Earth Engine...\")\n",
        "    ndvi_data = get_monthly_ndvi(start_date, end_date, study_area)\n",
        "\n",
        "    # study_area = STUDY_AREA\n",
        "\n",
        "    if ndvi_data is not None:\n",
        "        print(f\"จำนวนเดือนที่มีข้อมูล NDVI: {ndvi_data.size().getInfo()}\")\n",
        "\n",
        "        print(\"กำลังสร้างชุดข้อมูลรวม...\")\n",
        "        dataset = create_monthly_dataset(ndvi_data, study_area)\n",
        "\n",
        "        if dataset is not None:\n",
        "            print(\"กำลังแปลงข้อมูลเป็น DataFrame...\")\n",
        "            df = fc_to_df(dataset)\n",
        "            print(f\"จำนวนข้อมูลใน DataFrame: {len(df)} เดือน\")\n",
        "\n",
        "            if not df.empty and len(df) > 12:\n",
        "                print(\"ตัวอย่างข้อมูล:\")\n",
        "                print(df.head(10))\n",
        "                print(f\"\\nช่วงข้อมูล: {df['date'].min()} ถึง {df['date'].max()}\")\n",
        "\n",
        "                # === NEW: ADD TIME SERIES VISUALIZATIONS ===\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"กำลังสร้างกราฟการวิเคราะห์ Time Series ขั้นสูง...\")\n",
        "                print(\"=\"*60)\n",
        "\n",
        "                # 1. Comprehensive time series analysis\n",
        "                plot_ndvi_hotspot_time_series(df)\n",
        "\n",
        "                # 2. Yearly comparison analysis\n",
        "                plot_yearly_comparison(df)\n",
        "\n",
        "                # 3. Statistical analysis report\n",
        "                analysis_results = create_comprehensive_analysis_report(df)\n",
        "\n",
        "                print(\"\\n\" + \"=\"*60)\n",
        "                print(\"กำลังดำเนินการการสร้างแบบจำลองและทำนาย...\")\n",
        "                print(\"=\"*60)\n",
        "                # === END NEW VISUALIZATIONS ===\n",
        "\n",
        "                print(\"กำลังเตรียมข้อมูลสำหรับการฝึกแบบจำลอง...\")\n",
        "                try:\n",
        "                    X, y, scaler_x, scaler_y, df_cleaned = prepare_monthly_training_data(\n",
        "                        df, sequence_length=6, target_column='hotspot_count'\n",
        "                    )\n",
        "                    print(f\"ข้อมูลที่เตรียม: X.shape = {X.shape}, y.shape = {y.shape}\")\n",
        "\n",
        "                    # แบ่งข้อมูลฝึกและทดสอบ\n",
        "                    split_idx = int(len(X) * 0.8)\n",
        "                    X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "                    y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "                    print(f\"ข้อมูลฝึก: {X_train.shape}, ข้อมูลทดสอบ: {X_test.shape}\")\n",
        "\n",
        "                    # สร้างและฝึกแบบจำลอง\n",
        "                    print(\"กำลังสร้างแบบจำลอง LSTM...\")\n",
        "                    model = create_monthly_lstm_model(X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "                    if model is None:\n",
        "                        print(\"ไม่สามารถสร้างแบบจำลองได้ กรุณาตรวจสอบการติดตั้ง TensorFlow\")\n",
        "                        return\n",
        "\n",
        "                    print(\"กำลังฝึกแบบจำลอง...\")\n",
        "\n",
        "                    # เพิ่ม callbacks สำหรับการฝึกที่ดีขึ้น\n",
        "                    try:\n",
        "                        from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "                        early_stopping = EarlyStopping(\n",
        "                            monitor='val_loss',\n",
        "                            patience=15,\n",
        "                            restore_best_weights=True,\n",
        "                            verbose=1\n",
        "                        )\n",
        "\n",
        "                        reduce_lr = ReduceLROnPlateau(\n",
        "                            monitor='val_loss',\n",
        "                            factor=0.5,\n",
        "                            patience=10,\n",
        "                            min_lr=1e-7,\n",
        "                            verbose=1\n",
        "                        )\n",
        "\n",
        "                        callbacks = [early_stopping, reduce_lr]\n",
        "                    except ImportError:\n",
        "                        callbacks = []\n",
        "\n",
        "                    history = model.fit(\n",
        "                        X_train, y_train,\n",
        "                        epochs=100,  # เพิ่ม epochs\n",
        "                        batch_size=32,\n",
        "                        validation_data=(X_test, y_test) if len(X_test) > 0 else None,\n",
        "                        callbacks=callbacks,\n",
        "                        verbose=0\n",
        "                    )\n",
        "\n",
        "                    # 5. Add learning curve chart\n",
        "                    print(\"\\nกำลังสร้างกราฟ Learning Curve...\")\n",
        "                    plot_learning_curve(history)\n",
        "\n",
        "                    # ประเมินแบบจำลอง\n",
        "                    if len(X_test) > 0:\n",
        "                        print(\"\\nกำลังประเมินแบบจำลอง...\")\n",
        "                        y_pred = model.predict(X_test)\n",
        "                        y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n",
        "                        y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "                        print(\"ผลการประเมินแบบจำลอง:\")\n",
        "                        mse, rmse, mae, r2 = evaluate_model(y_test_rescaled, y_pred_rescaled)\n",
        "\n",
        "                        # 6. Add actual vs predict chart\n",
        "                        print(\"\\nกำลังสร้างกราฟ Actual vs Predicted...\")\n",
        "                        plot_actual_vs_predicted(\n",
        "                            y_test_rescaled.flatten(),\n",
        "                            y_pred_rescaled.flatten(),\n",
        "                            target_column='hotspot_count'\n",
        "                        )\n",
        "\n",
        "                    # ทำนาย 12 เดือนข้างหน้า\n",
        "                    print(\"\\nกำลังทำนาย 12 เดือนข้างหน้า...\")\n",
        "                    last_sequence = X[-1:]\n",
        "                    predictions, prediction_dates = predict_next_12_months(\n",
        "                        model, last_sequence, scaler_x, scaler_y, df_cleaned, sequence_length=6\n",
        "                    )\n",
        "\n",
        "                    print(\"การทำนายเสร็จสมบูรณ์!\")\n",
        "\n",
        "                    # สร้างตารางสรุป\n",
        "                    print(\"\\nกำลังสร้างตารางสรุปการทำนาย...\")\n",
        "                    pred_summary_df = create_prediction_summary_table(\n",
        "                        predictions, prediction_dates, target_column='hotspot_count'\n",
        "                    )\n",
        "\n",
        "                    # สร้างกราฟต่างๆ\n",
        "                    print(\"\\nกำลังสร้างกราฟการทำนาย 12 เดือน...\")\n",
        "                    plot_12_month_prediction(df_cleaned, predictions, prediction_dates, target_column='hotspot_count')\n",
        "\n",
        "                    print(\"\\nการวิเคราะห์และทำนาย HOTSPOT COUNT รายเดือนเสร็จสมบูรณ์!\")\n",
        "                    print(\"ไฟล์ที่สร้าง:\")\n",
        "                    print(\"  - learning_curve.png: กราฟ Learning Curve\")\n",
        "                    print(\"  - actual_vs_predicted.png: กราฟ Actual vs Predicted\")\n",
        "                    print(\"  - 12_month_prediction.png: กราฟการทำนาย 12 เดือน\")\n",
        "                    print(\"  - 12_month_hotspot_predictions.csv: ตารางผลการทำนาย\")\n",
        "\n",
        "\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"เกิดข้อผิดพลาดในการเตรียมข้อมูล: {e}\")\n",
        "                    import traceback\n",
        "                    print(\"รายละเอียดข้อผิดพลาด:\")\n",
        "                    traceback.print_exc()\n",
        "            else:\n",
        "                print(\"ข้อมูลไม่เพียงพอสำหรับการสร้างแบบจำลอง (ต้องการอย่างน้อย 12 เดือน)\")\n",
        "        else:\n",
        "            print(\"ไม่สามารถสร้างชุดข้อมูลได้\")\n",
        "    else:\n",
        "        print(\"ไม่สามารถดึงข้อมูล NDVI ได้\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "372f2a56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "372f2a56",
        "outputId": "1fb33a67-19c1-4e4d-83cb-f03b5203283d"
      },
      "outputs": [],
      "source": [
        "# เรียกใช้ฟังก์ชันหลัก\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize Earth Engine (ต้องทำการ authenticate ก่อน)\n",
        "    try:\n",
        "        main()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ไม่สามารถเชื่อมต่อ Google Earth Engine ได้: {e}\")\n",
        "        print(\"กรุณาตรวจสอบ:\")\n",
        "        print(\"   1. การติดตั้ง earthengine-api\")\n",
        "        print(\"   2. การ authenticate: ee.Authenticate()\")\n",
        "        print(\"   3. การเชื่อมต่ออินเทอร์เน็ต\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "udfire",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
